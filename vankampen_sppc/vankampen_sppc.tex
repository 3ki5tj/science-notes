\documentclass{book}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}

\hypersetup{
    colorlinks,
    linkcolor={red!30!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\renewcommand{\thechapter}{\Roman{chapter}}
\makeatletter
  \renewcommand\l@chapter{\@dottedtocline{2}{1.5em}{2.5em}}
  \renewcommand\l@section{\@dottedtocline{2}{2.5em}{3.5em}}
\makeatother


\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]

\theoremstyle{remark}
\newtheorem{rem}{Remark}

\begin{document}

% annotation macros
\newcommand{\repl}[2]{{\color{gray} [#1] }{\color{blue} #2}}
\newcommand{\add}[1]{{\color{blue} #1}}
\newcommand{\del}[1]{{\color{gray} [#1]}}
\newcommand{\note}[1]{{\color{OliveGreen}\small [\textbf{Comment.} #1]}}

\newcommand{\hl}[1]{{\color{red} #1}}

\title{Notes on \emph{Stochastic Process in Physics and Chemistry}\cite{vankampen}}
\author{N. G. Van Kampen}
\date{3rd Edition (May 7, 2007)}

\maketitle

\tableofcontents


\chapter{Stochastic Variables}

\section{Definition}

\begin{defn}
  A continuous \emph{probability distribution}
  (\emph{probability density}) is a function
  that satisfies
  \begin{equation}
    P(x) \ge 0
    \label{eq:Px_nonneg}
  \end{equation}
  and
  \begin{equation}
    \int P(x) \, dx = 1.
    \label{eq:Px_normalize}
  \end{equation}
\end{defn}

For a mixture of discrete and continuous distribution,
\begin{equation}
  P(x) = \sum_n p_n \, \delta(x - x_n) + \tilde P(x).
  \label{eq:Px_mixture}
\end{equation}

The normalization is
$$
\sum_{n} p_n + \int \tilde P(x) \, dx = 1.
$$

\subsection*{Excursus}

\begin{defn}
  The \emph{cumulative distribution function}
  (\emph{probability distribution function})
  is defined as
  \begin{equation}
    \mathbb{P}(x) = \int_{-\infty}^{x+0} P(x') \, dx'.
  \end{equation}
\end{defn}

\paragraph{Axiomatic probability theory.}

References\cite{kolmogorov}.

\begin{enumerate}
\item The $x$-axis $\rightarrow$ a set $S$.
\item An interval $dx$ $\rightarrow$ a subset $A \subset S$.
\item Each subset $A$ is assigned
  a nonnegative number $\mathcal P(A)$, such that
  $$
  \mathcal P(S) = 1.
  $$
  For disjoint $A$ and $B$,
  $$
  \mathcal P(A + B) = \mathcal P(A) + \mathcal P(B).
  $$
  This is called the \emph{probability measure}.
\end{enumerate}

\subsection*{Exercises}

\paragraph{Rencontre problem (Matching problem).}

What's the probability that an arbitrary permutation
of $n$ objects leaves no object in its place?

Using the hint, we have
$$
n \, p(n) - (n-1) \, p(n-1) = p(n-2).
$$

Then
$$
n \, [p(n) - p(n-1)] = - [ p(n-1) - p(n-2)].
$$
and
$$
p(n) - p(n-1) = \frac{ (-1)^{n} }{n!}.
$$
So
$$
p(n) = \sum_{i = 0}^n \frac{ (-)^{k} } { k! } \rightarrow e^{-1}.
$$


\section{Averages}

\section{Multivariate distributions}

\section{Addition of stochastic variables}

\section{Transformation of variables}

\section{The Gaussian distribution}

\section{The central limit theorem}




\chapter{Random Events}

\section{Definition}

\section{The Poisson distribution}

\section{Alternative description of random events}

\section{The inverse formula}

\section{The correlation functions}

\section{Waiting times}

\section{Factorial correlation functions}


\chapter{Stochastic Processes}

\section{Definition}

\section{Stochastic process in physics}

\section{Fourier transformation of stationary process}

\section{The hierarchy of distribution functions}

\paragraph{Stationary Process.}

A process is \emph{stationary} if all $P_n$ depend on the time difference alone.

$$
P_n(y_1, t_1 + \tau; y_2, t_2 + \tau; \cdots; y_n, t_n + \tau)
=
P_n(y_1, t_1; y_2, t_2; \cdots; y_n, t_n).
$$


\paragraph{Gaussian process.}

a process is \emph{Gaussian} if all $P_n$ are
(multivariate) Gaussian distributions.


\section{The vibrating string and random fields}

\section{Branching process}


\chapter{Markov Processes}


\section{Markov property}

\section{The Chapman-Kolmogorov equation}

Page 78.
A Markov process:
$$
P_{1|n-1}(y_n, t_n| y_1, t_1; \dots, y_{n-1}, t_{n-1})
=
P_{1|1}(y_n, t_n|y_{n-1},t_{n-1})
$$
where, $P_{1|1}$ is the transition probability.

Page 79.
Wiener process (Wiener-L\'evy process)
\begin{equation}
P_{1|1}(y_2, t_2|y_1, t_1)
=
\frac{1}{\sqrt{2\,\pi(t_2 - t_1)}}
\exp\left[
  -\frac{ (y_2 - y_1)^2 } { 2 \, (t_2 - t_1) }
\right].
\tag{2.4}
\end{equation}
%
\begin{equation}
P_1(y, t)
=
\frac{1}{\sqrt{2\,\pi\,t}}
\exp\left[
  -\frac{ y^2 } { 2 \, t }
\right].
\tag{2.5}
\end{equation}


Page 80.
Poisson process
\begin{equation}
P_{1|1}(n_2, t_2|n_1, t_1)
=
\frac{ (t_2 - t_1)^{n_2 - n_1} } { (n_2 - n_1)! }
e^{ -(t_2 - t_1) },
\tag{2.6}
\end{equation}
where
$P_1(n, 0) = \delta_{n,0}$.

Page 81. Ex. 5 Eq. (2.8)

$$
\frac{ \partial P } { \partial t }
=
D \frac{ \partial^2 P } { \partial y^2 }.
$$
Show (2.5) satisfies this by $D = \frac{1}{2}$.
Generally, try
$$
P = \frac{ 1 } { \sqrt{ 2 \, \pi \, a(t) } }
\exp\left(
  - \frac{ y^2 } { 2 \, a(t) }
\right).
$$
Then,
$$
\begin{aligned}
\frac{ \partial P } { \partial y }
&=
- \frac{ y } { a } P
\\
\frac{ \partial^2 P } { \partial y^2 }
&=
- \frac{1}{a} P
+ \frac{ y^2 } { a^2 } P
\\
\frac{ \partial P } { \partial t }
&=
-\frac{ a' } { 2 \, a } P
+ \frac{ y^2 } { 2 \, a^2 } a' P.
\end{aligned}
$$
So $a'(t) = 2 \, D(t)$,
and
$a(t) = 2 \int^t_0 D(s) \, ds$.


\section{3. Stationary Markov process}

Page 83.
Ornstein-Uhlenbeck (OU) process.
Phys. Rev. 36 823 (1930).
\begin{equation}
P_1(y_1)
=
\frac{1}{\sqrt{2 \, \pi} e^{-\frac 1 2 y_1^2 } }
\tag{3.10}
\end{equation}

\begin{equation}
  T_\tau(y_2 | y_1)
=
\frac{ 1 } { \sqrt{ 2 \, \pi \, (1 - e^{-2\tau}) }  }
\exp\left[
  -\frac{ (y_2 - y_1 e^{-\tau})^2 }
  { 2 ( 1 - e^{-2 \tau } ) }
\right]
\tag{3.11}
\end{equation}

Page 84.
Doob's theorem.
J. L. Doob Annals of Math. 43, 351 (1942).

If a process is stationary, Gaussian and Markovian,
essential OU is the only process with these properties.

Page 85.
Exercise 8. (3.11) satisfies
\begin{align}
\frac{ \partial T } { \partial \tau }
&=
\frac{ \partial } { \partial y_2 } \left( y_2 T \right)
+
\frac{ \partial^2 T } { \partial y_2^2 }
\quad \mathrm{forward}
\tag{3.20}
\\
\frac{ \partial T } { \partial \tau }
&=
-y_1 \frac{ \partial T } { \partial y_1 }
+
\frac{ \partial^2 T } { \partial y_1^2 }
\quad \mathrm{backward}
\tag{3.21}
\end{align}


Page 86.
Exercise 12.
Cauchy process.
\begin{equation}
  T_\tau(y_2|y_1)
  =
  \frac{1}{\pi}
  \frac{ \tau } { (y_2 - y_1)^2 + \tau^2 }.
\end{equation}
Prove it satisfies Chapman-Kolmogorov.
$$
\begin{aligned}
\int T_{\tau'}(y_3|y_2) T_\tau(y_2|y_1) \, dy_2
&=
\int \int \int \tilde T_\tau \, \tilde T_\tau' \,
e^{-i(k + k') y_2 } \frac{dk}{2\pi} \frac{dk'}{2\pi} dy_2
\\
&=
\int e^{ -i|k| (\tau +\tau') + ik (y_1 -y_3) } \frac{dk}{2\pi}
\\
&=
\frac{1}{\pi}
\frac{ \tau + \tau'}
{ (\tau + \tau')^2 + (y_3 - y_1)^2 } \\
&=
T_{\tau + \tau'}(y_3 | y_1) \\
\end{aligned}
$$



\section{The extraction of a subensemble}

\section{Markov chains}

\section{The decay process}


\chapter{The Master Equation}


\chapter{One-step Processes}


\chapter{Chemical reactions}


\chapter{The Fokker-Planck Equation}

\section{Introduction}

\begin{equation}
  \frac{ \partial P(y, t) }  { \partial t }
=
-\frac{\partial } {\partial y} A(y) P
+\frac{1}{2} \frac{ \partial^2 } { \partial y^2 } B(y) P.
\tag{1.1}
\end{equation}


\begin{equation}
\partial_t \langle y \rangle
= \langle A(y) \rangle.
\tag{1.7}
\end{equation}

$$
\partial_t \langle y \rangle
= A(\langle y \rangle).
$$

\section{Derivation of the Fokker-Planck equation}

\section{Brownian motion}

\section{The Rayleigh particle}

\section{Application to one-step process}

\section{The multivariate Fokker-Planck equation}

\begin{equation}
\frac{ \partial P } { \partial t }
=
-\sum_i \frac{ \partial } { \partial y_i } (A_i \, P)
+ \frac 1 2
\sum_{i, j} \frac{ \partial^2 } { \partial y_i \partial y_j } (B_{ij} P ).
\tag{6.1}
\end{equation}

To determine the parameters, we use
\begin{equation}
\begin{aligned}
\frac{ \langle \Delta y_i \rangle_y } { \Delta t }
&=
A_i(y), \\
\frac{ \langle \Delta y_i \, \Delta y_j \rangle_y } { \Delta t }
&=
B_{ij}(y).
\end{aligned}
\tag{6.3}
\end{equation}

The linear multivariate Fokker-Planck equation is
\begin{align}
\frac{  \partial P(y, t) } { \partial t }
=
-\sum_{i,j} A_{ij} \frac{ \partial } { \partial y_i } y_j P
+ \frac 1 2 \sum_{ij} B_{ij} \frac{ \partial^2 P } { \partial y_i \partial y_j },
\tag{6.4}
\end{align}

\section{Kramers' equation}

[
  This equation converts the position $X$ Fokkar-Planck equation
  to the position-velocity $X$-$V$ Fokkar-Planck equation.
]

\chapter{The Langevin Approach}

\section{Langevin treatment of Brownian motion}

\section{Applications}

\section{Relation of Fokker-Planck equation}

\section{The Langevin approach}

Page 230.

$$
\dot y = A(y) + C(y) L(t),
$$
where $L(t)$ is the Wiener process,
and $\langle L(t) L(t') \rangle = \Gamma \delta(t - t')$.


$$
\frac{ \partial P }{ \partial t }
=
-{ \partial } { \partial y } [ A(y) \, P ]
+
\frac{ \Gamma } { 2 } \frac{ \partial } { \partial y }
\left\{
  C(y)
  \frac{ \partial } { \partial y } [ C(y) \, P ]
\right\}.
$$

\section{Discussion of the It\^o-Stratonovich dilemma}

\section{Non-Gaussian white noise}

\section{Colored noise}

\chapter{The Expansion of the Master Equation}

\chapter{The Diffusion Type}

\chapter{First-passage Problems}

\chapter{Unstable Systems}

\chapter{Fluctuations in Continuous Systems}

\chapter{The Statistics of Jump Events}

\chapter{Stochastic Differential Equations}

\chapter{Stochastic Behavior of Quantum Systems}

\bibliographystyle{plain}
\bibliography{../simul}
\end{document}
