\documentclass{book}
\usepackage{amsmath}
\begin{document}


\chapter{5. Linear Systems}

\section{5.1 Definition and Examples}

The set of equations we are interested in is
$$
\begin{aligned}
  \mathbf {\dot x}
  &= \mathbf f(\mathbf x) \\
  &= \mathbf A \mathbf x.
\end{aligned}
$$
The $n\times n$ matrix $\mathbf A$ always has $n$ eigenvalues,
but not always have $n$ eigenvectors (see degenerate node below).
But if there are $n$ eigenvectors,
we can diagonalize the matrix by combinations of $x_i$,
i.e., for each $j = 1, \dots, n$, we have
$$
\dot v_j = \lambda_j v_j,
$$
where $v_j = \sum_{j = 1}^n c_{ji} x_i$.

\begin{itemize}

\item
Fixed point. A fixed point, $\mathbf x^*$, is the solution of
$$
\mathbf f(\mathbf x^*) = 0.
$$
In our case, $\mathbf x^* = \mathbf 0$ is the origin.

\item
Node.
If all eigenvalues share the same sign, then the fixed point is a \emph{node}.
If the sign is positive, it unstable; negative, stable.

\item
Star.
A special node with all eigenvalues being identical is a \emph{star}.

\item
Saddle points.
If the eigenvalues are all real, but some are positive, some are negative, the fixed point is saddle.
The space spanned the set of eigenvectors of the negative/positive eigenvalues are called the \emph{stable/unstable manifold}.

\item
Spiral.
In two dimensions, $n = 2$,
if the eigenvalues are complex numbers, then the fixed point is a \emph{spiral}.

\item
Center.
A special spiral with purely imaginary eigenvalues is a \emph{center}. For example,
\begin{align*}
  \dot x &= y \\
  \dot y &= -x,
\end{align*}
has two eigenvalues $\lambda = \pm i$.

\end{itemize}


\subsection{Stability Language}


\begin{itemize}

\item
Attracting.
If any trajectory starting from somewhere near the fixed point, $\mathbf x^*$, ultimately approaches $\mathbf x^*$, then $\mathbf x^*$ is \emph{attracting}.

\item
Globally attracting.
If any trajectory starting from anywhere ultimately approaches $\mathbf x^*$, then $\mathbf x^*$ is \emph{globally attracting}.

\item
Lyapunov stable.
A fixed point, $\mathbf x^*$, is \emph{Lyapunov stable} if all trajectories starting close to $\mathbf x^*$ remain close to it at all times.

\item
\emph{Neutrally stable} means Lyapunov stable but not attracting.  An example is a center.

\item
\emph{Asymptotically stable} means Lyapunov stable and attracting.

\end{itemize}




\section{5.2 Classification of linear systems}


In two-dimensions, our equation becomes
\begin{equation}
  \mathbf {\dot x}
  = \mathbf A \mathbf x
  = \left(
    \begin{array}{cc}
      a_{11} & a_{12} \\
      a_{21} & a_{22}
    \end{array}
  \right)
  \mathbf x.
\end{equation}
The characteristic equation is
$|\mathbf A - \lambda| = 0$,
with the eigenvalues being
$\lambda_{1,2} = \frac 1 2 \left(\tau \pm \sqrt{\tau^2 -  4 \Delta} \right)$,
where
$$
\begin{aligned}
  \tau &= \mathrm{Tr} \mathbf A = a_{11} + a_{22} = \lambda_1 + \lambda_2, \\
  \Delta &= \mathrm{det} \mathbf A = a_{11} a_{22} - a_{12} a_{21} = \lambda_1 \, \lambda_2.
\end{aligned}
$$

The fixed point can be classified as follows.

\begin{itemize}

\item
If $\Delta < 0$, the eigenvalues are real with opposite signs.  So it is a saddle point.

\item
If $0 < \Delta < \tau^2/4$, the eigenvalues are real with the same sign.  So it is a node.  If $\tau = \lambda_1 + \lambda_2$ is positive, the node is unstable; otherwise, stable.

\item
If $\Delta > \tau^2/4$, both eigenvalues are complex.  So it is a spiral or a center.  If $\tau > 0$, it is an unstable spiral; if $\tau < 0$, a stable one; it $\tau = 0$ or $\lambda_1 = -\lambda_2$, a center.

\end{itemize}



\subsection{Conserved quantity}



Suppose we have the two eigenvectors, with
$$
\begin{aligned}
  \dot v_1 &= \lambda_1 v_1 \\
  \dot v_2 &= \lambda_2 v_2,
\end{aligned}
$$
then it is readily show that
$$
\frac{d}{dt} (\ln v_1^{1/\lambda_1} - \ln v_2^{1/\lambda_2}) = 0,
$$
or
$$
v_1^{1/\lambda_1} v_2^{-1/\lambda_2} = \mathrm{const.}
$$


Particularly, if $\lambda_1 = -\lambda_2$,
or the fixed the point is a center,
then $v_1 v_2$ is a constant.
This can be simplified as
\begin{align}
A =
\frac{a_{21}}{2 \, a_{11}} \, x_1^2
+\frac{a_{12}}{2 \, a_{22}} \, x_2^2
-x_1 x_2
= \mathrm{const.}
\label{eq:2lin_conserved}
\end{align}
This quadratic form gives the closed orbit of the center,
which is an ellipse.
%
In fact,
$$
\frac{dA}{dt}
=
-\Delta \left(\frac{1}{a_{11}} + \frac{1}{a_{22}} \right) \, x_1 \, x_2,
$$
vanishes when the trace is zero, or $a_{11} + a_{22} = 0$,
which is equivalent to the fact that $\lambda_1 + \lambda_2 = 0$.


An easier way to derive \eqref{eq:2lin_conserved} is the following,
$$
\begin{aligned}
0 &= \dot x_1 \dot x_2 - \dot x_2 \dot x_1 \\
  &= (a_{11} x_1 + a_{12} x_2) \, \dot x_2
   - (a_{21} x_1 + a_{22} x_2) \, \dot x_1 \\
  &= \frac{d}{dt} \left(
   \frac{1}{2} a_{12} x_2^2
   -\frac{1}{2} a_{21} x_1^2
   + a_{11} x_1 x_2
 \right).
\end{aligned}
$$
To show that the above quantity is proportional to $v_1 v_2$,
we expanded the latter using
$$
\begin{aligned}
  v_1 &= a_{21} x_1 + (\lambda_1 - a_{11}) x_2, \\
  v_2 &= a_{21} x_1 + (\lambda_2 - a_{11}) x_2,
\end{aligned}
$$
with $\lambda_1 + \lambda_2 = 0$, and
$\lambda_1 \lambda_2 = a_{11} a_{22} - a_{12} a_{21} = -a_{11}^2 - a_{12} a_{21}$.

The method of conserved quantity for the nonlinear case
is discussed in \S 6.5 of the book.




\subsection{Degenerate node}


A \emph{degenerate node} occurs if only one eigenvector exists.
This happens when two eigenvalues are the same.
For example, if the matrix, $\mathbf A$, assumes the form of
$$
\mathbf A =
\left(
  \begin{array}{cc}
    \lambda & b \\
    0 & \lambda
  \end{array}
\right),
$$
with $b \ne 0$,
then both eigenvalues are $\lambda$, but only one eigenvector $(1, 0)^T$ exists.
Generally, if the two eigenvalues are the same,
the fixed point is either a degenerate node or a star (the $b = 0$ case).
The matrix is a rotational invariant for the star,
but not for the degenerate node.
The explicit solution for $(x_1, x_2) = (x, y)$ is
\begin{equation}
\begin{aligned}
  x &= (x_0 + b \, y_0 \, t) \, e^{\lambda t} \\
  y &= y_0 \, e^{\lambda t}.
\end{aligned}
\label{eq:degenode}
\end{equation}


\subsubsection{Limit of a node}

A degenerate node can be thought as the limiting case two nearly identical eigenvalues.  Consider
$$
\mathbf A =
\left(
  \begin{array}{cc}
    \lambda_1 & b \\
    0 & \lambda_2
  \end{array}
\right),
$$
whose two eigenvalues are $\lambda_1$ and $\lambda_2$,
and the corresponding eigenvectors are
$(1, 0)^T$ and $(1, \frac{\lambda_2 - \lambda_1}{b})$,
respectively.
The explicit solution is
$$
\begin{aligned}
  x &= \left(x_0 + b \, y_0 \frac{ \exp[(\lambda_2 - \lambda_1) t] - 1 }{\lambda_2 -\lambda_1} \right) \, e^{\lambda_1 t} \\
  y &= y_0 \, e^{\lambda_2 t},
\end{aligned}
$$
which indeed recovers \eqref{eq:degenode} as $\lambda_2 \rightarrow \lambda_1$.


\subsubsection{Borderline case of a node and a spiral}

A degenerate node can be thought as the borderline case of a node and a spiral.  Consider
$$
\mathbf A_N =
\left(
  \begin{array}{cc}
    \lambda & b \\
    \epsilon^2/b & \lambda
  \end{array}
\right),
$$
with a small $\epsilon$.
The two eigenvalues are $\lambda_{1,2} = \lambda \pm \epsilon$,
with the corresponding eigenvectors being $(b, \mp \epsilon)$.
The fixed point is therefore a node.
Now consider
$$
\mathbf A_S =
\left(
  \begin{array}{cc}
    \lambda & b \\
    -\epsilon^2/b & \lambda
  \end{array}
\right),
$$
The two eigenvalues are $\lambda_{1,2} = \lambda \pm \epsilon i$,
with the corresponding eigenvectors being $(b, \mp \epsilon i)$.
The fixed point is therefore a spiral.
The explicit solution,
$$
\begin{aligned}
  x &= \left[x_0 \, \cos(\epsilon t)+ b \, y_0 \frac{ \sin(\epsilon t) }{\epsilon} \right] \, e^{\lambda t} \\
  y &= \left[b \, y_0 \, \cos(\epsilon t) - \epsilon x_0 \, \sin(\epsilon t) \right] \, e^{\lambda t},
\end{aligned}
$$
also recovers \eqref{eq:degenode} as $\epsilon \rightarrow 0$.


\subsubsection{Backbending}

The degenerate node shows a backbending trajectory.  Starting from $x_0 > 0, y_0 > 0$, the trajectory will first reach a negative $x$ before converging to the fixed point.
Differentiate the first equation of \eqref{eq:degenode} with respect to $t$, we get
$$
0 = (x_0 + b \, y_0 \, t_m) \lambda \, e^{\lambda t} + b \, y_0 \, e^{\lambda t_m}
= \lambda \, x_m + b \, y_0 \, e^{\lambda t_m},
$$
which means the minimal $x$, or $x_m$ in the above, is negative.


\section{Love affairs}

The section studied special cases of the two-dimensional linear equation.
To make it more interesting, $x_1$ and $x_2$ are replaced by $R$ and $J$,
interpreting Romeo and Juliet's love and hate to the other.
For example, $R > 0$ ($< 0$) means Romeo loves (hates) Juliet.
The equations are then
\begin{equation}
\begin{aligned}
  \dot R &= a R + b J, \\
  \dot J &= c R + d J.
\end{aligned}
\label{eq:RJ}
\end{equation}



\subsection{Ratio method}

Here we'll give an alternative method to the book.
The method helps reduce the number of cases by considering only the ratio $R/J$.
This is useful because often $(-R, -J)$ satisfies the same equation
as \eqref{eq:RJ}.
By considering the ratio, we effectively eliminate this degeneracy.


We convert \eqref{eq:RJ} to
\begin{equation}
  \frac{d}{dt} \left( \frac R J \right)
  =
  b + (a - d) \left( \frac R J \right) - c \left( \frac R J  \right)^2,
  \label{eq:RoverJ}
\end{equation}
which becomes a one-dimensional problem in term of $r \equiv R/J$.
\begin{equation}
  \frac{dr}{dt}
  =
  b + (a - d) \, r - c \, r^2.
  \label{eq:diffeq_r}
\end{equation}
So, we only need to find out the fixed points of $r$
and analyze their stabilities.


Now if the polynomial, $b + (a - d) \, r - c \, r^2$,
has two real zeros, then the larger one is stable if $c > 0$,
or the smaller one is stable if $c < 0$.
%
If the polynomial has no real zero of $r$, it means a spiral or a center.
What usually happens is that $r$ continually increases
from $-\infty$ to $+\infty$, and wraps back to $-\infty$,
completing a cycle.


In fact, we can directly integrate \eqref{eq:RoverJ},
$$
\frac{R}{J}
=
\frac{a - d}{2 c}
-\frac{ \sqrt D }{2 c}
\tanh\frac{ \sqrt D \, t } { 2 },
$$
where $D = (a - d)^2 + 4 \, b \, c$.


Now if $D > 0$, as $t \rightarrow 1$, $\tanh (\sqrt D \,t /2) \rightarrow 1$.
We get a zero of the polynomial, which is larger root if $c < 0$,
or the smaller one if $c > 0$, agreeing with the above discussion.

If $D < 0$, then $\tanh(\sqrt D \, t/2) = \tan(\sqrt{-D} \, t/2)$,
and $R/J$ varies periodically, we then get a spiral or a center.
Unfortunately, the method cannot tell the difference between
a spiral and a center.  One way to do this is to see if
$$
\frac{1}{2} \frac{c}{a} R^2 + \frac{1}{2} \frac{b}{d} J^2 - R J
$$
is a constant.  If so, it's likely a center.



\subsubsection{Integral}


The integral used in the ratio method is evaluated as follows
$$
\begin{aligned}
t &= \int \frac { dr } { A \, r^2 + B \, r + C } \\
  &= \int \frac { dr } { A \, (r - r_1) \, (r - r_2) } \\
  &= \frac{1}{A(r_2 - r_1)}
  \int \frac{ (r - r_1) - (r - r_2) }
  { (r - r_1) (r - r_2) } \, d r \\
  &= \frac{1}{A(r_2 - r_1) }
  \ln \left( \frac{ r_2 - r } { r - r_1 } \right),
\end{aligned}
$$
where we have assumed $r_1 < r_2$ for the case of two real roots.

Then
\begin{equation}
r =
\frac{r_1 + r_2}{2}
-
\frac{r_2 - r_1}{2}
\tanh\frac{A \, (r_2 - r_1) (t - t_0)}{2}.
\label{eq:intg_r}
\end{equation}
Note that this expression is an even function of $r_2 - r_1$,
so the sign of $r_2 - r_1$ can be decided arbitrarily.
%
Now, since
$$
\begin{aligned}
  r_1 + r_2 &= - \frac B A, \\
  r_1 \, r_2 &= \frac C A,
\end{aligned}
$$
we have
$$
r_2 - r_1 = \frac{ \sqrt{ B^2 - 4 \, A \, C } }{ A }.
$$
Using this in \eqref{eq:intg_r} yields
$$
r = \frac{B}{2A} - \frac{\sqrt{B^2 - 4AC}}{2A} \tanh\frac{\sqrt{B^2 -4AC}\Delta t}{2}.
$$





% Chapter 6
\chapter{Phase Plane}

In the previous chapter, we studied a special case of
\begin{equation}
  \mathbf{\dot x} = \mathbf f(\mathbf x),
  \label{eq:diffeq}
\end{equation}
in which $\mathbf f(\mathbf x) = \mathbf A \mathbf x$ is linear.
Here we will studied the general case.


\section{6.1 Phase portraits}

Definitions

\begin{itemize}

\item
A \emph{phase portrait} is plotted by following the trajectory of
$\mathbf x = (x_1, x_2)$ along the flow $\mathbf{\dot x} = (\dot x_1, \dot x_2)$.

\item
A \emph{fixed point} is where $\mathbf{\dot x} = \mathbf 0$.
Unlike the linear system, in which the fixed point is unique,
which is set to $\mathbf 0$ in the previous chapter.
In general, we can have multiple fixed points.

\item
A \emph{closed orbit} satisfies $\mathbf x(t + T) = \mathbf x(t)$ for any $t$
and some $T > 0$.

\item
\emph{Nullclines} are curves where either $\dot x_1 = 0$ or $\dot x_2 = 0$.

\end{itemize}



\subsection{Runge-Kutta method}

The Runge-Kutta method is a method of solving \eqref{eq:diffeq}.

$$
\begin{aligned}
\mathbf x_{n+1} &= \mathbf x_n + \frac{1}{6} (\mathbf k_1 + 2 \, \mathbf k_2 + 2 \, \mathbf k_3 + \mathbf k_4), \\
\mathbf k_1 &= \mathbf f(\mathbf x_n) \, \Delta t, \\
\mathbf k_2 &= \mathbf f(\mathbf x_n + \frac 1 2 \mathbf k_1) \, \Delta t, \\
\mathbf k_3 &= \mathbf f(\mathbf x_n + \frac 1 2 \mathbf k_2) \, \Delta t, \\
\mathbf k_4 &= \mathbf f(\mathbf x_n + \mathbf k_3) \, \Delta t.
\end{aligned}
$$


\section{6.2 Existence, uniqueness and topological consequences}


The solution of $\mathbf{\dot x} = \mathbf f(\mathbf x)$,
$\mathbf x(\mathbf 0) = \mathbf x_0$ exists and is unique.

A corollary is that trajectories never intersect.

Another important corollary is that a trajectory start inside a closed orbit $C$ stays in the $C$ forever.

\emph{Poincar\'e-Bendixson theorem.}
If a trajectory is confined in a closed region, and there is no fixed point inside the region, then the trajectory must ultimately approach a closed orbit.


\section{6.5 Conserved systems}


This section introduces a technique useful
in proving the existence of a closed orbit.
%
If there is a non-constant quantity $E(\mathbf x) = E(x_1, x_2)$
such that $dE/dt = 0$, like the energy in mechanics,
and the curve defined by
\begin{equation}
E(x_1, x_2) = \mathrm{constant}.
\label{eq:conserveE}
\end{equation}
encloses an isolated fixed point,
then closed orbits exist,
and they are just the curves defined by \eqref{eq:conserveE}.



Another interesting lemma is that in conservative system,
no stable/unstable fixed point exists.
This is because the time evolution starting from
a nearby point preserves the conserved quantity, $E(\mathbf x)$.
So if a trajectory ultimately flows into the fixed point,
it means the fixed point share the same value of $E(\mathbf x)$
as the starting point.
Thus the entire neighborhood of the fixed point must
share the same value of $E(\mathbf x)$,
meaning that $E(\mathbf x)$ is a constant function,
contradicting the definition.


\subsection{Finding the conserved quantity}



From the definition, a conserved quantity can be found from integrating
\begin{equation}
\frac{dx_2}{dx_1}
=
\frac{\dot x_2}{\dot x_1}
=
\frac{f_2(\mathbf x)}{f_1(\mathbf x)},
\label{eq:conserved_trace}
\end{equation}
which is a differential equation between $x_2$ and $x_1$ (the time dependence is eliminated).
But integrating such a curve of $x_2$ and $x_1$ can be difficult.
So we use the following method.


Eq. \eqref{eq:conserved_trace} is equivalent to
$$
0 =
-f_2 \, d x_1
+f_1 \, d x_2.
$$
We wish to multiply the right-hand side by a quantity $g$
such that it becomes a total differential
$$
dE(x_1, x_2)
=
-g \, f_2(\mathbf x) \, d x_1
+g \, f_1(\mathbf x) \, d x_2,
$$
then obviously we have $dE/dt = 0$.
Now this the requires the consistency of the first order derivatives, namely
$$
\frac{\partial (-g \, f_2)}{\partial x_2}
=
\frac{\partial^2 E}{\partial x_1 \partial x_2}
=
\frac{\partial (g \, f_1)}{\partial x_1},
$$
or
\begin{equation}
\nabla \cdot (g \, \mathbf f)
=
\frac{\partial (g f_1)}{\partial x_1}
+\frac{\partial (g f_2)}{\partial x_2}
= 0.
\label{eq:divgf_eq_0}
\end{equation}
Note the similarity to Dulac's criterion (\S 7.2).
There, we want to show that the same quantity has the same sign within a certain region in order rule out the existence of closed orbits.
Here we are doing the opposite.
By showing the quantity is identically zero, we prove the existence of closed orbits.

In component form, the above equation is (after divided by $g$)
\begin{equation}
\left( \frac{\partial f_1}{\partial x_1}
+\frac{\partial f_2}{\partial x_2} \right)
+\left(
\frac{\partial \ln g }{\partial x_1} f_1
+\frac{\partial \ln g }{\partial x_2} f_2
\right)
=0.
\label{eq:divfdivlng}
\end{equation}
The first term is independent of $g$.
If it is nonzero, our job is design a $\ln g$
that makes the second term cancel the first one,
which is relatively easier.


\end{document}
