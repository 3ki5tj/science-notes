%\documentclass[reprint,aip,jcp,superscriptaddress]{revtex4-1}
\documentclass[aip,jcp,preprint,superscriptaddress]{revtex4-1}
\usepackage{amsmath}
\usepackage{bm}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}

\hypersetup{
    colorlinks,
    linkcolor={red!30!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}


\begin{document}



\newcommand{\vct}[1]{\mathbf{#1}}
\newcommand{\vx}{\vct{x}}
\newcommand{\vy}{\vct{y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\Ham}{\mathcal{H}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\com}{\mathrm{com}}

\newcommand{\llbra}{[\![}
\newcommand{\llket}{]\!]}

% annotation macros
\newcommand{\repl}[2]{{\color{gray} [#1] }{\color{blue} #2}}
\newcommand{\add}[1]{{\color{blue} #1}}
\newcommand{\del}[1]{{\color{gray} [#1]}}
\newcommand{\note}[1]{{\color{OliveGreen}\small [\textbf{Comment.} #1]}}





\title{Weighted histogram analysis method (WHAM)
and related free energy methods}
%\author{ \vspace{-10ex} }
%\date{ \vspace{-10ex} }


\begin{abstract}
  We review a few free energy methods,
  including the famous weighted histogram analysis method (WHAM).
\end{abstract}

\maketitle

\tableofcontents



\section{What is WHAM and what does it do?}



The main purpose of this article is
to give a detailed discussion on
a beautiful free energy calculation method called
the weighted histogram analysis method (WHAM)\cite{
ferrenberg1988, *ferrenberg1989, kumar1992,
newman, frenkel}.
%
The method is widely useful because
it gives the most precise results
among a large class of similar methods.
%
Nonetheless, as we shall see,
it can be derived from some very rudimentary arguments.



Although WHAM is a general free energy method,
we shall discuss it in the context of the following case.
%
Suppose we have performed Monte Carlo (MC) simulations of a given system,
at several temperatures $\beta_1$, $\beta_2$, \dots, $\beta_K$.
%
Here $\beta = 1/(k_B T)$ denotes the inverse temperature,
with $k_B$ being the temperature.
%
We can then readily compute the average energy, heat capacity, etc.,
at these temperatures.


Now the first question is that
can we also \emph{rigorously} compute these quantities at a temperature,
say $\beta = (\beta_1 + \beta_2)/2$, which is not simulated?
%
A cheap answer such as a linear interpolation, for example,
would be biased and inefficient.
%
WHAM, on the other hand,
would give a better solution.
%
The quantities computed from WHAM will be
most accurate (unbiased)
and precise (with minimal errors).
%
The idea is that even if we only care about the quantities
at a particular temperature,
the data from \emph{all} simulated temperatures
can be combined in an unbiased way
to improve the estimates of the quantities.



Besides, WHAM will provide accurate
estimates for the partition function,
or, equivalently, the free energy,
which is usually something valuable
but hard-to-get.
%
This is why WHAM is usually introduced
as a free energy method.




\section{Basics}



\subsection{Canonical ensemble}



To start, we need to cover some basic concepts and formulae.
%
For simplicity,
we assume a quantum system with discrete energy levels.
%
The density of states, $g(E)$, is defined as the number of states
sharing the same energy $E$.
%
This $g(E)$
is the partition function of
the microcanonical ensemble.
%
In the canonical ensemble,
the partition function
at a certain temperature $\beta$
is given by
%
\begin{equation}
  e^{-f(\beta)} = Z(\beta) = \sum_E g(E) \, \exp(-\beta \, E),
  \label{eq:Z_def}
\end{equation}
%
where,
we have also introduced
a dimensionless free energy $f\equiv -\log Z$.



The energy distribution is given by
%
\begin{equation}
  p_\beta(E) = g(E) \, \frac{ \exp(-\beta \, E) } { Z(\beta) }.
  \label{eq:pE_def}
\end{equation}
%
It is clear from Eq. \eqref{eq:Z_def}
that we have the normalization:
\begin{equation}
  \sum_E p_\beta(E) = 1.
  \label{eq:pE_normalization}
\end{equation}
%



With the energy distribution,
we can compute the average of any quantity,
$A(E)$, that can be expressed as a function of $E$:
%
\begin{equation}
  \langle A(E) \rangle_\beta
=
  \sum_E A(E) \, p_\beta(E).
  \label{eq:pE_average}
\end{equation}
%
If we want the average energy,
we simply set $A(E) = E$.



From a simulation at temperature $\beta$,
we can collect an energy histogram, $n_\beta(E)$,
whose entries sum to the sample size.
%
\begin{equation}
  N_\beta = \sum_E n_\beta(E).
  \label{eq:nE_sum}
\end{equation}
%
The observed energy histogram
should match the theoretical distribution
\begin{equation}
  \frac{ \langle n_\beta(E) \rangle } { N_\beta }
=
  p_\beta(E)
=
  g(E) \frac{ \exp(-\beta \, E) } { Z(\beta) }.
  \label{eq:nE}
\end{equation}




\subsection{General distribution}



A similarly set of formulae
can be derived for a general ensemble
with weight $q(E)$.
%
\begin{equation}
  Z_q = \sum_E g(E) \, q(E).
  \label{eq:Zq_def}
\end{equation}
%
with the energy distribution is given by
%
\begin{equation}
  p_q(E) = g(E) \, \frac{ q(E) } { Z_q },
  \label{eq:pqE_def}
\end{equation}
%
which is also properly normalized.


For a simulation done in this ensemble,
we have, similar to Eq. \eqref{eq:nqE}
\begin{equation}
  \frac{ \langle n_q(E) \rangle_q } { N_q }
=
  p_q(E)
=
  g(E) \frac{ q(E) } { Z_q }.
  \label{eq:nqE}
\end{equation}





\section{Deriving WHAM}



\subsection{Estimating the density of states}


We have now all the tools needed to derive WHAM.
%
An important observation from
Eqs. \eqref{eq:pE_def} and \eqref{eq:pqE_def}
is that
the energy distributions at different ensembles
differ only by the ensemble weight,
which is $w_\beta(E) = \exp(-\beta \, E) / Z(\beta)$
for the canonical ensemble,
or $w_q(E) = q(E)/Z_q$ in the general case.
%
The common part, the density of states,
$g(E)$, is the key for WHAM.
%
If we can accurately estimate $g(E)$
then for any temperature, $\beta$,
we can compute $Z(\beta)$ from Eq. \eqref{eq:Z_def},
and Eq. \eqref{eq:pE_def} gives the distribution,
hence, any average quantities.
%
Thus,
the central task of WHAM
is to estimate $g(E)$ accurately.




\subsection{Composite ensemble}



The simplest way
of estimating $g(E)$ is through the histogram equation,
Eq. \eqref{eq:nE}:
%
\begin{align}
\hat g(E)
=
\frac{ n_\beta(E) }
{ N_\beta \, \exp(-\beta \, E) / Z(\beta) }
=
\frac{ n_\beta(E) }
{ N_\beta \, w_\beta(E) }
\label{eq:gE_onehistogram}
\end{align}
for some $\beta = \beta_k$.
%
This is obviously not the most efficient way,
because we are only using the data
from a single simulation.
%
To improve this,
we naturally would like to include data
from all simulations.
%
Here is how to do it.



Consider a composite ensemble
of the $K$ canonical ensembles.
%
The histogram of this ensemble
is obviously the overall histogram
%
\begin{equation}
  n_\com(E)
=
  \sum_{k = 1}^K n_k(E).
  \label{eq:ncom_def}
\end{equation}
%
If we sum over $E$,
we should get the total sample size
%
\begin{equation}
 \sum_{k = 1}^K N_k
= N_\com
= \sum_E n_\com(E)
\label{eq:ncom_sum}
\end{equation}
%


Let us now find the ensemble weight, $w_\com(E)$,
of the composite ensemble.
%
But, by the nature of the ensemble,
this should be a linear combination
of the weight of the member canonical ensembles,
with the sample sizes serving as the relative weight.
%
\begin{equation}
w_\com(E)
=
\sum_{k = 1}^K
\frac{ N_k } { N_\com }
w_{\beta_k}(E)
=
\sum_{k = 1}^K
\frac{ N_k } { N_\com }
\frac{ \exp( -\beta_k \, E ) } { Z(\beta_k) }
\end{equation}



Now let us solve $g(E)$
for the composite ensemble,
from an analogy of Eq. \eqref{eq:gE_onehistogram}:
%
\begin{align}
\hat g(E)
=
\frac{ n_\com(E) }
{ N_\com \, w_\com(E) }
=
\frac{ \sum_{k = 1}^K n_k(E) }
{ \sum_{k = 1}^K N_k \, \exp( -\beta_k \, E ) / Z(\beta_k) }.
\label{eq:gE_WHAM}
\end{align}
%
Since this is based on the all data we have,
it should be the most precise estimate of $g(E)$.




\subsection{Iterative solution}


This is it!
%
Equation \eqref{eq:gE_WHAM} is the key equation of WHAM.
%
But, wait, we don't know $Z(\beta_k)$ yet,
how can we use them in Eq. \eqref{eq:gE_WHAM}?
%
Well, this is done iteratively.
%
Initially,
we can guess a set of arbitrary $Z(\beta_k)$,
say,
\[
  Z^{(0)}(\beta_1) = \dots = Z^{(0)}(\beta_K) = 1.
\]
%
Plugging these numbers to Eq. \eqref{eq:gE_WHAM}
yields a $g^{(1)}(E)$.
%
Then, we use this $g(E)$ in Eq. \eqref{eq:Z_def}
to compute a new set of
$Z^{(1)}(\beta_k)$.
%
This time, the numbers should be better
than those from the last time.
%
Keep doing the two steps will yield
a set of converged
$Z^{(\infty)}(\beta_k)$,
and the corresponding density of states
$g^{(\infty)}(E)$,
which are invariant under the iteration.
%
These are the solution of the WHAM equation.







\bibliography{../simul}
\end{document}
