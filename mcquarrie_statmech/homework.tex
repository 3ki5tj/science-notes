\documentclass[reprint]{revtex4-1}

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{hyperref}
\usepackage{listings}

\hypersetup{
    colorlinks,
    linkcolor={red!30!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolor}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolor},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\numberwithin{equation}{section}

% define the problem and solution environments
\definecolor{problue}{rgb}{0.2,0.2,0.5}
\newenvironment{problem}
{\par\medskip\sffamily \color{problue}
  \textbf{Problem. }\ignorespaces}
{\medskip}

\newenvironment{solution}
{\par\medskip
  \textbf{Solution. }\ignorespaces}
{\medskip}



\begin{document}
\title{Homework problems for McQuarrie's Statistical Mechanics, \\
  based on Dr. B. M. Pettitt's lectures}
%\author{\vspace{-10ex}}
%\date{\vspace{-10ex}}
\maketitle

\tableofcontents

\section{Notes}

In this section, we collect a few results that are helpful in problem solving.

\section{Lecture 1: Mechanics vs. Statistical Mechanics}

\subsection{Problem 1-5}

\subsection{Problem 1-14}

\subsection{Problem 1-28}

\subsection{Problem 1-30}


\section{Lecture 2: Probability and Distributions}

\subsection{Problem 1-41}

\subsection{Problem 1-44}

\subsection{Problem 1-46}

\subsection{Programming problem}

\begin{problem}
Write a program and draw $10$ random numbers between $-1$ and $+1$,
add them together and divide by $10$ and save it.
Do this $100$ times, $1000$ times and $100,000$ times.
Plot the distributions as histograms using only $10$ points on the $x$-axis.
\end{problem}

\begin{solution}
Here is a sample code in Python.
\begin{lstlisting}[language=Python]
import random
def randsum(ntimes):
    # initialize an empty histogram of 10 bins
    hist = [0]*10
    dx = 2.0/10 # set the bin width
    for t in range(ntimes):
        # add 10 random numbers between -1 and 1
        s = 0
        for i in range(10):
            s += random.random()*2 - 1
        s /= 10 # divide the sum by 10
        # find the bin index
        binid = int((s + 1) / dx)
        # update the histogram
        hist[binid] += 1
    # compute the distribution and plot it
    print "\nDistribution, %d trials:" % ntimes
    for binid in range(10):
        y = hist[binid]/(ntimes*dx) # normalize
        bar = "#" * int(y*50)
        print "%10.8f%s" % (y, bar)

randsum(100)
randsum(1000)
randsum(100000)
\end{lstlisting}
\end{solution}




\section{Lecture 3. Thermodynamics and Entropy}

\subsection{Problem 1-52}

\subsection{Problem 1-59}


\section{Lecture 4: Second and Third Laws}

\subsection{Problem 1-51}

\subsection{Problem 2-6}

\subsection{Problem 2-8}

\section{Lecture 5: Idea of Ensembles}

\subsection{Programming problem}

\begin{problem}
Write a program to estimate $\pi$ from Monte Carlo integration.
%
Pick points randomly on a unit square.
%
Some points will lie inside a circle inscribed in the square,
some outside.
%
Use the ratio of the hits inside to the total number of trials
to estimate the area of the circle and therefore $\pi$.
%
How does it converge with the number of attempts.
\end{problem}

\begin{solution}
A sample Python program is listed below.
The error should scale
with the number of sampling points, $N$,
as $1/\sqrt N$.

\begin{lstlisting}[language=Python]
import math, random
def estpi(n):
    hits = 0
    for i in range(n):
        x = random.random() * 2 - 1
        y = random.random() * 2 - 1
        if x*x + y*y < 1:
            hits += 1
    p = 4.0*hits/n
    print "pi %g, error %g" % (p, p - math.pi)

estpi(10000)
\end{lstlisting}
\end{solution}



\section{Lecture 6: The Principles of A Priori Probabilities}

\subsection{Problem 2-11}

\subsection{Problem 2-13}

\section{Lecture 7: Partition Functions and the Use of Ensembles}

\subsection{Problem 2-16}

\subsection{Problem 2-17}

\section{Lecture 8: The Canonical Ensemble}

\subsection{Problem 3-4}

\subsection{Problem 3-6}

\section{Lecture 9: Grand Canonical Ensemble}

\subsection{Problem 3-15}

\subsection{Problem 3-17}

\subsection{Problem 3-24}

\section{Lecture 10: Fluctuations}

\subsection{Problem 3-22}

\begin{problem}
Show that the fluctuation in energy in a grand canonical ensemble is
$$
\sigma_E^2 = k \, T^2 \, C_V
  + \left( \frac{\partial \overline E } { \partial \overline N} \right)_{T, V} \sigma_N^2
$$
\end{problem}

\paragraph*{Interpretations.}

There is probably a typo here, since the units do not match.
%
The most likely fix is
\begin{equation}
  \sigma_E^2 = k \, T^2 \, C_V
  + \left( \frac{\partial \overline E }
                { \partial \overline N} \right)_{T, V}
    \sigma_N^2 \, \textcolor{red}{\times \mu}
  \label{eq:prob3-22a}
\end{equation}
%
Another possible fix is
%
\begin{equation}
  \sigma_E^2 = k \, T^2 \, C_{V,\textcolor{blue}{N}}
  + \left( \frac{\partial \overline E }
                { \partial \overline N} \right)_{T, V}^{\textcolor{blue}{2}}
    \sigma_N^2
  \label{eq:prob3-22b}
\end{equation}
%
In the second correction,
$C_V$ is interpreted as the heat capacity in the canonical ensemble,
so it is less likely.

\begin{solution}
We will show Eq. \eqref{eq:prob3-22a} first.
The partition function of the grand canonical ensemble, $\Xi$,
is defined as a superposition of
the partition functions of the canonical ensemble, $Q(N, V, T)$
at various numbers of particles, $N$:
%
\begin{align}
\Xi
  &=
  \sum_{N} Q(N, V, T) \, z^N
  \notag \\
  &=
  \sum_{N, E} \Omega(N, V, E) \, e^{-\beta \, E + \mu^* \, N}
,
  \label{eq:Xi_def}
\end{align}
%
where we have defined the reduced chemical potential $\mu^* = \beta \, \mu = \ln z$.
%
As $\ln \Omega$ corresponds to the entropy $S/k$,
$\ln Q$ corresponds to the Helmholtz free energy $S/k - \beta \, E = -\beta \, A$,
the free energy corresponding to $\ln \Xi$
is the so-called grand potential:
%
\begin{equation}
  \ln \Xi
  = \frac{S}{k} - \beta \, E + \mu^* N
  = \beta \, p \, V
  .
  \label{eq:lnXi}
\end{equation}
Here, the last step follows from Euler's theorem,
$E = T \, S - p \, V + \mu \, N$ [cf. Eq. \eqref{eq:Euler}].
%
By differentiating Eq. \eqref{eq:Xi_def}, we get
%
\begin{align*}
  \frac{ \partial \Xi } { \partial \beta }
  &=
  \sum_{N, E} \Omega(N, V, E) \cdot (-E) \cdot e^{-\beta \, E + \mu^* N}
  \\
  &=
  -\Xi \,
  \sum_{N, E} E \cdot \frac{ \Omega(N, V, E) \, e^{-\beta \, E + \mu^* N} } { \Xi }
  \\
  &=
  -\Xi \times \overline{E}
  ,
\end{align*}
%
where we have collected
$\Omega(N, V, E) \, e^{-\beta \, E + \mu^* N}/\Xi$
as the joint distribution of $E$ and $N$
in the grand canonical ensemble.
%
Dividing both sides by $-\Xi$,
we get
\begin{align}
  \overline E
  &=
  -\frac{ \partial \Xi } { \Xi \, \partial \beta }
  =
  -\frac{ \partial \ln \Xi } { \partial \beta }
  ,
  \label{eq:dXidbeta}
\end{align}
Similarly, by differentiating Eq. \eqref{eq:Xi_def}
with respect to $\mu^*$, we get
\begin{align}
  \overline N &= \frac{ \partial \ln \Xi } { \partial \mu^* }
  .
  \label{eq:dXidmu}
\end{align}
%
Combining the above two results, we get
\begin{equation}
  d \ln \Xi
  =
  \frac{ \partial \ln \Xi } { \partial \beta } d\beta
  +
  \frac{ \partial \ln \Xi } { \partial \mu^* } d\mu^*
  = -\overline E \, d\beta + \overline N \, d\mu^*
  .
  \label{eq:firstlawXi}
\end{equation}
%
We can compare this to the first law of thermodynamics,
%
\begin{align*}
  dE
  &= T \, dS - p \, dV + \mu \, dN
  ,
  \\
  d\left(\frac{S}{k} \right)
  &= \beta \, dE + \beta \, p \, dV - \mu^* \, dN
  ,
  \\
  d\left(\frac{S}{k} - \beta \, E \right)
  &= -E \, d\beta + \beta \, p \, dV - \mu^* \, dN
  ,
  \\
  d\left(\frac{S}{k} - \beta \, E + \mu^* N \right)
  &= -E \, d\beta + \beta \, p \, dV + N \, d\mu^*
  .
\end{align*}
%
By Eq. \eqref{eq:lnXi},
we recognize the last expression
is the differential of $\ln Xi$,
and with a fixed volume, $V$
it becomes
%
\begin{equation}
  d\ln \Xi = -E \, d\beta + N \, d\mu^*
  .
  \label{eq:firstlawXi2}
\end{equation}
%
Thus, to make the statistical mechanical expression, Eq. \eqref{eq:firstlawXi},
agree with the thermodynamical expression, Eq. \eqref{eq:firstlawXi2},
we should interpret $E$ and $N$ in the latter
as the ensemble averages, $\overline E$ and $\overline N$, respectively.
%
We can further differentiate
Eqs. \eqref{eq:dXidbeta} and \eqref{eq:dXidmu}
to get fluctuations of $E$ and $N$:
%
\begin{align}
  \sigma_E^2
  &=
  -\left( \frac{ \partial \overline E } { \partial \beta } \right)_{\mu^*, V}
  = \frac{ \partial^2 \ln \Xi } { \partial \beta^2 }
  ,
  \label{eq:varE}
  \\
  \sigma_N^2
  &= \left( \frac{ \partial \overline N } { \partial \mu^* } \right)_{\beta, V}
  = \frac{ \partial^2 \ln \Xi } { \partial \mu^{*2} }
  \label{eq:varN}
  ,
  \\
  \left( \frac{ \partial \overline E } { \partial \mu^* } \right)_{\beta, V}
  &= -\frac{ \partial^2 \ln \Xi } { \partial \mu^* \, \partial \beta }
  = - \left( \frac{ \partial \overline N } { \partial \beta } \right)_{\mu^*, V}
  \label{eq:covEN}
  .
\end{align}

Now the heat capacity in the grand-canonical ensemble can be defined as
%
\begin{align}
C_V
&= \left( \frac{ T \, \partial S } { \partial T } \right)_{\mu^*, V}
\notag \\
&= -\beta \left( \frac{ \partial S } { \partial \beta } \right)_{\mu^*, V}
= -\frac{1}{T} \left( \frac{ \partial (S/k) } { \partial \beta } \right)_{\mu^*, V}.
\label{eq:CV_def}
\end{align}
%
Using Eq. \eqref{eq:lnXi}, we have
\begin{align}
-T \, C_V
  &= \left( \frac{ \partial (\ln \Xi + \beta \, \overline E - \mu^* \, \overline N) }
  { \partial \beta } \right)_{\mu^*, V}.
  \notag
  \\
  &= \frac{ \partial \ln \Xi } { \partial \beta }
  + \overline E
  + \beta \left( \frac{ \partial \overline E } { \partial \beta } \right)_{\mu^*, V}
  - \mu^* \left( \frac{ \partial \overline N } { \partial \beta } \right)_{\mu^*, V}
  \notag
  \\
  &=
  - \beta \, \sigma_E^2
  + \mu^* \left( \frac{ \partial \overline E } { \partial \mu^* } \right)_{\beta, V}
  ,
  \notag
\end{align}
%
where we have used Eqs. \eqref{eq:dXidbeta}, \eqref{eq:varE}, and \eqref{eq:covEN}
in the last step.
%
Further using Eq. \eqref{eq:varN}, we have
\begin{equation}
T \, C_V
=
\beta \, \sigma_E^2
-
\mu^* \,
\frac{ \left( \partial \overline E / \partial \mu^* \right)_{\beta, V} }
     { \left( \partial \overline N / \partial \mu^* \right)_{\beta, V} }
\, \sigma_N^2
.
\label{eq:TCV}
\end{equation}
%
Finally, if we interpret
$$
\frac{ \left( \partial \overline E / \partial \mu^* \right)_{\beta, V} }
     { \left( \partial \overline N / \partial \mu^* \right)_{\beta, V} }
\to
\left(
  \frac{ \partial \overline E }
       { \partial \overline N }
\right)_{T, V}
,
$$
and multiply both sides of Eq. \eqref{eq:TCV} by $k T = 1/\beta$,
we recover Eq. \eqref{eq:prob3-22a}.

\paragraph*{Additional notes: Euler's theorem.}

For a single-component system, we have
the following useful equation
\begin{equation}
  E = T \, S - p \, V + \mu \, N.
\label{eq:Euler}
\end{equation}
%
We can show this from McQuarrie's Eq. (1-60),
$$
G = \sum_i \mu_i \, N_i
$$
But by definition $G = E - TS + pV$, so
%
$$
  E = T \, S - p \, V + \sum_i \mu_i \, N_i.
$$
%
The one-component case gives Eq. \eqref{eq:Euler}.

\paragraph*{Second interpretation.}

About the second interpretation, Eq. \eqref{eq:prob3-22b},
we will use the advanced technique of transforming thermodynamic variables
(i.e. chain rule),
so please ignore this section if it sounds unfamiliar.
%
Similar to Eq. \eqref{eq:CV_def},
the heat capacity in the canonical ensemble is defined as
\begin{equation}
C_{V, N}
= -\frac{1}{T} \left( \frac{ \partial S^* } { \partial \beta } \right)_{V, N},
  \label{eq:CVN_def}
\end{equation}
where we have introduced $S^* = S/k$ for convenience.
%
To be clear, the heat capacity in the grand-canonical ensemble
will be denoted as
\begin{equation}
C_{V, \mu^*} = -\frac{1}{T} \left( \frac{ \partial S^* } { \partial \beta } \right)_{V, \mu^*}.
  \label{eq:CVmu_def}
\end{equation}
%
Using the technique of determinants for transforming variables, we have
\begin{align*}
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{\mu^*}
  &=
  \frac{ \partial (S^*, \mu^*) } { \partial (\beta, \mu^*) }
  =
  \left.
  \frac{ \partial (S^*, \mu^*) } { \partial (\beta, N) }
  \middle/
  \frac{ \partial (\beta, \mu^*) } { \partial (\beta, N) }
  \right.
  \\
  &=
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{N}
  -
  \left.
  \left( \frac{ \partial \mu^* } {\partial \beta } \right)_{N}
  \left( \frac{ \partial S^* } {\partial N } \right)_{\beta}
  \middle/
  \left( \frac{ \partial \mu^* } {\partial N } \right)_{\beta}
  \right.
\end{align*}
From the first law, we have
$$
d(S^* - \beta \, E) = -E \, d\beta -\mu^* dN + \beta p \, dV
,
$$
%
so
\begin{align*}
  \left( \frac{ \partial \mu^* } {\partial \beta } \right)_{N}
  &=
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  ,
  \\
  \left( \frac{ \partial S^* } {\partial N } \right)_{\beta}
  &=
  \left( \frac{ \partial (S^* - \beta \, E) } {\partial N } \right)_{\beta}
  +
  \left( \frac{ \partial ( \beta \,  E) } {\partial N } \right)_{\beta}
  \\
  &=
  -\mu^*
  +
  \beta \, \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  .
\end{align*}
Using the above two expressions, we get
\begin{align*}
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{\mu^*}
  &=
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{N}
  +
  \mu^* \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  \left( \frac{ \partial N } {\partial \mu^* } \right)_{\beta}
  \\
  &-
  \beta \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}^2
  \left( \frac{ \partial N } {\partial \mu^* } \right)_{\beta}
  .
\end{align*}
%
Dividing both sides by $-1/(k T) = -\beta$,
and using Eqs. \eqref{eq:CVN_def}, \eqref{eq:CVmu_def}, and \eqref{eq:varN},
we get
$$
  k T^2 C_{V, \mu^*}
  +
  \mu \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  \sigma_N^2
  =
  k T^2 C_{V, N}
  +
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}^2
  \sigma_N^2
  .
$$
If we interpret
$\left( \partial E / \partial N \right)_{\beta}$
as
$\left( \partial \overline E / \partial \overline N \right)_{T, V}$,
we recover Eq. \eqref{eq:prob3-22b}.
Note that we have implicitly assumed that $V$ is fixed in the above derivation.
\end{solution}


\subsection{Problem 3-23}

\begin{problem}
Show that in a two-component open, isothermal ensemble that
  \begin{align*}
    \overline{ N_1 \, N_2 }
    - \overline{N_1} \, \overline{N_2}
    &=
    kT \left(
      \frac{ \partial \overline{ N_1 } }
           { \partial \mu_2 }
      \right)_{V, T, \mu_1}
    \\
    &=
    kT \left(
      \frac{ \partial \overline{ N_2 } }
           { \partial \mu_1 }
      \right)_{V, T, \mu_2}
  \end{align*}
\end{problem}

\begin{solution}
The partition function of the grand canonical ensemble, $\Xi$,
is defined as a superposition of
the partition functions of the canonical ensemble, $Q(N_1, N_2, V, T)$
at various numbers of particles, $N_1$ and $N_2$,
of the two species:
\begin{align}
\Xi(\mu_1, \mu_2, V, T)
=
\sum_{N_1, N_2=0}^\infty
  Q(N_1, N_2, V, T) \,
  e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}.
\label{eq:Xi2_def}
\end{align}
%
This means that the joint distribution of $N_1$ and $N_2$
would be given by
$$
p(N_1, N_2) = \frac{ Q(N_1, N_2, V, T) \, e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2} }
                   { \Xi(\mu_1, \mu_2, V, T) }.
$$
By differentiating Eq. \eqref{eq:Xi2_def},
we have
\begin{align}
  \frac{ \partial \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 }
  &=
  \sum_{N_1, N_2}
    (\beta \, N_1) \times Q \cdot
    e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}
  \label{eq:dXi2_dmu1a}
  \\
  &=
    \beta \, \Xi \cdot
    \sum_{N_1, N_2}
    N_1 \times p(N_1, N_2)
  \notag
  \\
  &=
    \beta \, \Xi \cdot
    \overline{ N_1 }
  .
  \label{eq:dXi2_dmu1c}
\end{align}
%
Dividing both sides by $\Xi$, we get
%
\begin{align*}
  \frac{ \partial \ln \Xi } { \partial \mu_1 }
  = \beta \cdot \overline{ N_1 },
\end{align*}
%
Similarly, we have
\begin{align}
  \frac{ \partial \ln \Xi } { \partial \mu_2 }
  = \beta \cdot \overline{ N_2 },
  \label{eq:dlnXi2_dmu2}
\end{align}
%
If we further differentiate Eq. \eqref{eq:dXi2_dmu1a}
with respect to $\mu_2$, then
\begin{align*}
  \frac{ \partial^2 \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 \partial \mu_2 }
  &=
  \sum_{N_1, N_2}
    Q \cdot (\beta^2 \, N_1 \, N_2) \cdot
    e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}
  \\
  &=
    \beta^2 \, \Xi \cdot
    \sum_{N_1, N_2}
    p(N_1, N_2) \cdot (N_1 \, N_2)
  \\
  &=
  \beta^2 \, \Xi \, \overline{ N_1 \, N_2 }
  .
\end{align*}
%
But if we differentiate Eq. \eqref{eq:dXi2_dmu1c}
with respect to $\mu_2$,
\begin{align*}
  \frac{ \partial^2 \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 \partial \mu_2 }
  &=
    \beta \, \frac{ \partial \Xi } { \partial \mu_2 } \cdot
    \overline{ N_1 }
    +
    \beta \, \Xi \cdot
    \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  \\
  &=
    \beta^2 \, \Xi \cdot
    \overline{ N_2 } \, \overline{ N_1 }
    +
    \beta \, \Xi \cdot
    \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
\end{align*}
%
where we have used Eq. \eqref{eq:dlnXi2_dmu2} in the second step.
To make the two expressions agree, we have
$$
  \beta^2 \, \Xi \, \overline{ N_1 \, N_2 }
  =
  \beta^2 \, \Xi \cdot
  \overline{ N_2 } \, \overline{ N_1 }
  +
  \beta \, \Xi \cdot
  \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
$$
and by eliminating $\beta^2 \, \Xi$
on both sides, we get
$$
  \overline{ N_1 \, N_2 }
  =
  \overline{ N_2 } \, \overline{ N_1 }
  +
  kT \,
  \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
$$
%
which is the desired result.
%
The second equation can be shown by swapping the indices for $1$ and $2$.
\end{solution}




\section{Lecture 11: Quantum vs. Classical Statistics}

\section{Lecture 12: Ideal Monatomic Gas}

\subsection{Derive the thermodynamic potential for $(\mu, p, T)$}

\begin{problem}
Derive the thermodynamic potential for the $(\mu, p, T)$ ensemble.
\end{problem}

\begin{solution}
The answer is that no such thermodynamic potential exists.

If there were a thermodynamic potential for the $(\mu, p, T)$ ensemble,
the independent variables would be $\beta$, $\beta \, p$ and $\beta \, \mu$.
%
The partition function would look like
\begin{align*}
  \Psi
  &=
  \sum_V \Xi(N, V, \beta) \, e^{-\beta \, p \, V}
  \\
  &=
  \sum_V \sum_N Q(N, V, \beta) \, e^{\beta \, \mu \, N} \, e^{-\beta \, p \, V}
  \\
  &=
  \sum_V \sum_N \sum_E \Omega(N, V, E) \, e^{-\beta \, E}
  \, e^{\beta \, \mu \, N} \, e^{-\beta \, p \, V}
  .
\end{align*}
%
Let us now recall the process of mapping
partition functions to thermodynamic potentials.
%
For the microcanonical ensemble,
we map the logarithm of the density of states,
$\ln \Omega(N, V, E)$,
to the entropy, $S/k$.

The canonical partition function is
$Q(N, V, T) = \sum_E \Omega(N, V, E) \, e^{-\beta \, E}$,
and its logarithm corresponds to
$$
\ln Q(N, V, T) = S/k - \beta \, E = -\beta \, A,
$$
where $A = E - T \, S$ is the Helmholtz free energy.

Similarly, the partition function
of the grand canonical ensemble is
$\Xi(\mu, V, T) = \sum_N Q(N, V, T) \, e^{\beta \, \mu \, N}$,
and its logarithm corresponds to
$$
\ln \Xi(\mu, V, T) = \ln Q(N, V, T) + \beta \, \mu \, N = -\beta \, (A - \mu \, N).
$$
But from Euler's theorem, $E = T \, S - p \, V + \mu \, N$
[cf. Eq. \eqref{eq:Euler}], we know that
$$
A - \mu N = E - T S - \mu N = -p \, V,
$$
and
\begin{equation}
  \ln \Xi(\mu, V, T) = \beta \, p \, V.
\label{eq:lnXi_bpV}
\end{equation}

Finally, for our thermodynamic potential, $\Psi(\mu, V, T)$,
we would have
$$
\ln \Psi(\mu, p, T) = \ln \Xi(\mu, V, T) - \beta \, p \, V.
$$
But from Eq. \eqref{eq:lnXi_bpV},
the expression on the right-hand side is simply zero,
which means that such a thermodynamic potential
would not exist (under the above mapping to thermodynamics).
\end{solution}

\paragraph*{Another explanation.}

There is actually a simpler explanation.
%
A thermodynamic potential must be an extensive quantity,
which means that it should grow linearly with the system size.
%
But since $\mu$, $p$, and $T$ are all intensive quantities,
there is no way to specify how big the system is
and to write down the thermodynamic potential.

\paragraph*{Further discussion.}

The above argument is based on thermodynamics.
%
If we rely completely on the mathematics of statistical mechanics,
we will find that either $\ln \Psi(\mu, p, T)$
would vanish in the thermodynamic limit,
i.e. its magnitude is $\mathcal O(1)$,
or the integral for $\Psi(\mu, p, T)$ would diverge.
%
It is instructive to see this on the ideal-gas case.
%
Here, we have
\begin{align*}
  Q(N, V, T)
  &= \frac{(V/\Lambda^3)^N} {N!}, \\
  \Xi(\mu, V, T)
  &= \sum_{N=0}^\infty Q(N, V, T) \, e^{\beta \mu N}
  =
  \exp\left[
    \frac{ V \, e^{\beta \mu} } { \Lambda^3 }
  \right]
  .
\end{align*}
Then, for $\Psi(\mu, p, T)$, we have
$$
\Psi(\mu, p, T)
=\sum_{V}
  \exp\left[
    \frac{ V \, e^{\beta \mu} } { \Lambda^3 }
  \right]
  e^{-\beta \, p \, V}
\equiv
\sum_{V} e^{-\beta \, (p - p^*) \, V},
$$
where $p^* = kT \, e^{\beta \mu}/\Lambda^3$
%
Since the volume is continuous,
we should replace the sum $\sum_V \cdots$
with an integral $\int C(V) \, dV \cdots$
with some proper coefficient, $C(V)$.
%
If we assume that
$C(V)$ is a constant that does not depend on $V$,
then
\begin{align*}
\Psi(\mu, p, T)
&\propto
\int_0^\infty dV \, e^{-\beta \, (p - p^*) \, V}
\\
&=
\begin{dcases}
  \frac{1}{\beta (p - p^*)} & \mbox{if $p > p^*$} \\
  +\infty & \mbox{if $p \le p^*$},
\end{dcases}
\end{align*}
%
In the case of $p \ge p^*$,
although $\Psi(\mu, p, T)$ exists,
its magnitude is of order $\mathcal O(1)$,
i.e. $\ln \Psi(\mu, p, T)$
is not an extensive quantity,
and hence cannot represent a physical thermodynamic potential.


\subsection{Problem 5-9}


\subsection{Problem 5-14}


\section{Lecture 13: Ideal Diatomic Gas}

\subsection{Problem 6-19}

\subsection{Show that when $kT \gg h\nu$, $q_\mathrm{vib} = kT/(h\nu)$.}

\begin{problem}
Show that when $kT \gg h\nu$, $q_\mathrm{vib} = kT/(h\nu)$.
\end{problem}

\begin{solution}
We start from the quantum mechanical expression,
$$
q_\mathrm{vib} = \frac{e^{-\beta h\nu/2}}{1- e^{-\beta h\nu}}.
$$
Since $kT \gg h\nu$, we have $\beta h\nu \ll 1$,
which allows us to use the series expansion on $x = \beta h \nu$
around $x = 0$:
%
$$
e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots \approx 1 + x.
$$
%
So, with $x = \beta h \nu$ and $x = \beta h \nu/2$, we get
$$
e^{-\beta h \nu} \approx 1 - \beta h \nu,
\quad
\mbox{and}
\quad
e^{-\beta h \nu/2} \approx 1 - \beta h \nu/2.
$$
Thus,
$$q_\mathrm{vib} \approx
\frac{1-\beta h\nu/2}{1- (1-\beta h\nu)}
\approx
\frac{1}{\beta h\nu} = \frac{kT}{h\nu}.
$$
\end{solution}


%\section{Lecture 14: Classical Statistical Mechanics}
%
%\subsection{Problem 7-15}
%
%\subsection{Problem 7-16}
%
%\paragraph{Hint: use 7-15.}
%
%\subsection{Problem 7-18}
%
%\section{Lecture 15: Classical Mechanics and Phase Space}
%
%\subsection{Problem 7-6}
%
%\paragraph{Hint: see 2-16, i.e. $q \sim \sinh(E)$.}
%
%\subsection{Problem 7-17}
%
%\section{Lecture 16: Classical Phase Space}
%
%\section{Lecture 17: Crystals, Glasses, and Polymers}
%
%\section{Lecture 18: Imperfect Gases}
%
%\section{Lecture 19: Classical Monatomic liquids}
%
%\section{Lecture 20: Density Distributions and Correlation Functions}
%
%\section{Lecture 21: Evaluating Correlation Functions}
%
%\section{Lecture 22: Equilibria and Multi-Component Systems}
%
%\section{Lecture 23: Thermodynamic Perturbation Theory}
%
%\section{Lecture 24: Electrolyte Solutions}

\end{document}

