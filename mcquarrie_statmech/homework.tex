%\documentclass[preprint]{revtex4-1}
\documentclass[twocolumn, 10pt]{article}

\usepackage{mathrsfs}
\usepackage[margin=0.6in]{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\hypersetup{
    colorlinks,
    linkcolor={red!30!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\setlength{\columnsep}{0.3in}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolor}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolor},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\numberwithin{equation}{section}

% define the problem and solution environments
\definecolor{problue}{rgb}{0.2,0.2,0.5}
\newenvironment{problem}
{\par\medskip\sffamily \color{problue}
  \textbf{Problem. }\ignorespaces}
{\medskip}

\newenvironment{solution}
{\par\medskip
  \textbf{Solution. }\ignorespaces}
{\medskip}



\begin{document}
\title{Homework problems for McQuarrie's Statistical Mechanics, \\
  based on Dr. B. M. Pettitt's lectures}
\author{\vspace{-10ex}}
\date{\vspace{-10ex}}
\maketitle

\tableofcontents

\section*{Notes}

In this section, we collect a few results that are helpful in problem solving.

\subsection{Physical constants}

\begin{table}[h]\centering\small
  \begin{tabular}{l l}
    Constant & Value \\
    \hline \\
    Boltzmann constant, $k$ or $k_B$ &
    $1.38064852\times10^{-23} \, \mathrm{J/K}$
    \\
    Avogadro constant, $N_A$ &
    $6.022140857\times10^{23} \, \mathrm{mol}^{-1}$
    \\
    Planck constant, $h$ &
    $6.626070040\times10^{-34} \, \mathrm{J\cdot s}$
    \\
    Atmospheric pressure, $p_0$ &
    $101325 \, \mathrm{Pa}$
  \end{tabular}
\end{table}


\section{Lecture 1: Mechanics vs. Statistical Mechanics}

\subsection{Problem 1-5}

\begin{problem}
  Show that
  $$\xi(t) = A \, \sin \omega t + B \, \cos \omega t$$
  can be written as
  $$\xi(t) = C \, \sin( \omega t + \phi)$$
\end{problem}

\begin{solution}
Introducing $C = \sqrt{A^2 + B^2}$,
and
$$\phi = \pm \cos^{-1} \left( \frac A C \right),$$
with the sign ``$\pm$'' determined by that of $B$,
then $A = C \cos\phi$, $B = C \sin\phi$, and
$$
\xi(t) = C \, \cos\phi \, \sin \omega t + C \, \sin\phi \cos \omega t
= C \, \sin(\omega t + \phi).
$$
\end{solution}


\subsection{Problem 1-14}

\begin{problem}
If $H$, the classical Hamiltonian, does not depend explicitly on time,
show that $dH/dt = 0$.
What does this mean physically?
Is this true if $H$ does depend explicitly upon time?
\end{problem}

\begin{solution}
If the Hamiltonian does not depend explicitly on time,
its time dependence lies in $p_j$ and $q_j$
\begin{align*}
  \frac{dH}{dt}
  &= \sum_j
  \frac{ \partial H } { \partial p_j}
  \frac{ d p_j } { d t }
   +
  \frac{ \partial H } { \partial q_j}
  \frac{ d q_j } { d t }
  \\
  &= \sum_j
  \frac{ \partial H } { \partial p_j}
  \left( - \frac{ \partial H } { \partial q_j} \right)
   +
  \frac{ \partial H } { \partial q_j}
  \left( \frac{ \partial H } { \partial p_j} \right)
  = 0,
\end{align*}
where we have used Newton's equation
on the second line
\begin{align*}
  \frac{ d p_j } { d t }
  &=
  - \frac{ \partial H } { \partial q_j}
  ,
  \\
  \frac{ d q_j } { d t }
  &= \frac{ \partial H } { \partial p_j}
  .
\end{align*}
This means the energy is conserved.
This, however, is not true if $H$ does depend on time.
%
In fact, we can show that
$$
  \frac{ d H } { d t }
  =
  \frac{ \partial H } { \partial t }
  ,
$$
which is not necessarily zero.
\end{solution}


\subsection{Problem 1-28}

\begin{problem}
  Derive the thermodynamic equation
  $$
  C_p - C_V
  = \left[ p + \left( \frac{ \partial E } { \partial V } \right)_T \right]
  \left( \frac{ \partial V } { \partial T } \right)_p
  $$
  and evaluate this difference for an ideal gas
  and a gas that obeys the van der Waals equation.
\end{problem}

\subsection{Problem 1-30}

\begin{problem}
  Derive this equation
  $$
  dE = \left[ T \left( \frac{ \partial p} {\partial T } \right)_V - p \right]
  dV + C_V dT
  $$
  and from this show that $(\partial E/\partial V)_T = a/V^2$
  for a van der Waals gas.
\end{problem}

\section{Lecture 2: Probability and Distributions}

\subsection{Problem 1-41}

\begin{problem}
  Show that $\overline{ (x - \bar x)^2 } = \overline{ x^2 } - \bar x^2$.
\end{problem}

\begin{solution}
\begin{align*}
  \overline{ (x - \bar x)^2 }
  =
  \overline{ x^2  - 2 x \bar x + {\bar x}^2 }
  =
  \overline{ x^2 } - 2 \bar x \bar x + {\bar x}^2
  =
  \overline{ x^2 }  - {\bar x}^2.
\end{align*}
\end{solution}

\subsection{Problem 1-44}

\begin{problem}
  For the Gaussian distribution $p(x)$ show that

  (a)
  $$\int_{-\infty}^\infty p(x) \, dx  = 1$$

  (b)
  Calculate the $n$th central moment
  where $n = 0$, $1$, $2$, and $3$.

  (c)
  In the limit $\sigma \to 0$
  what kind of distribution is approached where
  $$
  p(x) = \frac{1}{\sigma \sqrt{2\pi}}
  \exp\left( -\frac{ (x -\bar x)^2 } { 2 \sigma^2} \right)
  $$
\end{problem}

\subsection{Problem 1-46}

\begin{problem}
  Let $f(x, y)$ be a joint probability density,
  that is, $f(x, y)\, dx \, dy$
  is the probability that $X$ lies between $x$ and $x+dx$
  \emph{and}
  $Y$ lies between $y$ and $y + dy$.
  If $X$ and $Y$ are \emph{independent}, then
  $$
  f(x, y) \, dx \, dy = f_1(x) f_2(y) \, dx \, dy
  $$
  If $X$ and $Y$ are independent, show that the mean and variance
  of their sum is equal to the sum of the means and variances, respectively,
  of $X$ and $Y$;
  that is, show that if $W = X + Y$, then
  \begin{align*}
    \overline W &= \overline X + \overline Y \\
    \overline{ (W - \overline W)^2 } &=
    \overline{ (X - \overline X)^2 } +
    \overline{ (Y - \overline Y)^2 }
  \end{align*}
\end{problem}

\begin{solution}
  For the average
  \begin{align*}
    \overline W
    &=
    \int \int (x + y) f_1(x) f_2(y) \, dx \, dy
    =
    \int \int x f_1(x) f_2(y) \, dx \, dy
    +
    \int \int y f_1(x) f_2(y) \, dx \, dy
    \\
    &=
    \int x \, f_1(x) \, dx \int f_2(y) \, dy
    +
    \int y \, f_2(y) \, dy \int f_1(x) \, dy
  \end{align*}
\end{solution}

\subsection{Programming problem}

\begin{problem}
Write a program and draw $10$ random numbers between $-1$ and $+1$,
add them together and divide by $10$ and save it.
Do this $100$ times, $1000$ times and $100,000$ times.
Plot the distributions as histograms using only $10$ points on the $x$-axis.
\end{problem}

\begin{solution}
Here is a sample code in Python.
\begin{lstlisting}[language=Python]
import random
def randsum(ntimes):
    # initialize an empty histogram of 10 bins
    hist = [0]*10
    dx = 2.0/10 # set the bin width
    for t in range(ntimes):
        # add 10 random numbers between -1 and 1
        s = 0
        for i in range(10):
            s += random.random()*2 - 1
        s /= 10 # divide the sum by 10
        # find the bin index
        binid = int((s + 1) / dx)
        # update the histogram
        hist[binid] += 1
    # compute the distribution and plot it
    print "\nDistribution, %d trials:" % ntimes
    for binid in range(10):
        y = hist[binid]/(ntimes*dx) # normalize
        bar = "#" * int(y*50)
        print "%10.8f%s" % (y, bar)

randsum(100)
randsum(1000)
randsum(100000)
\end{lstlisting}
\end{solution}




\section{Lecture 3. Thermodynamics and Entropy}

\subsection{Problem 1-52}

\begin{problem}
  Consider the sum
  $$
  \sum_{N=0}^M \frac{ M! x^N } { N! (M-N)! }
  $$
  where $x = \mathcal O(1)$,
  and $M$ and $N$ are $\mathcal O(10^{20})$.
  First show that
  $\ln\Sigma = M \ln(1+x)$
  \emph{exactly}, and then calculate
  the logarithm of the maximum term.
  Hint: Remember the binomial expansion.
\end{problem}

\begin{solution}
The sum is equal to $\Sigma = (1+x)^M$ by the binomial theorem,
and $\ln \Sigma = M \ln(1+x)$.

To find the maximum term,
we compute the ratio of two successful terms,
$$
  \frac{ T_N } { T_{N - 1} }
  =
  \frac{ M - N + 1 } { N } x.
$$
If the ratio is greater/less than $1$,
the term is increasing/decreasing.
Thus the maximum is reached when
  $T_N/T_{N-1} \ge 1 \ge T_{N+1}/T_N$, or
$$
  \frac{ M - N + 1} { N } x
  \ge 1 \ge
  \frac{ M - N } { N + 1 } x,
$$
which $N \approx M x /(1+x)$.
The logarithm of the maximum term is
\begin{align*}
  \ln T_N
  &= \ln M! + N \ln x - \ln N! - \ln (M-N)!
\end{align*}
%
Using the Stirling approximation, Eq. \eqref{eq:Stirling1},
we get
\begin{align*}
  \ln T_N
  &\approx M \ln M - N \, \ln N - (M - N) \, \ln(M-N) \\
  &\quad + N \ln x
  -\frac{1}{2} \ln\frac{2\pi N \, 2\pi(M-N)}{2\pi M}
  \\
  &=- N \, \ln \frac{N}{M} - (M - N) \, \ln\left(1-\frac{N}{M}\right) \\
  &\quad + N \ln x
  -\frac{1}{2} \ln\frac{2\pi N (M-N)}{M}
  \\
  &=
  N \, \ln\left( \frac{M-N}{N} \, x \right)
  + M \, \ln \frac{M}{M-N}
  \\
  &\quad -\frac{1}{2} \ln\frac{2\pi N (M-N)}{M}
  \\
  &\approx
  M\ln(1+x) - \ln\frac{ \sqrt{2\pi M x} } { 1 + x}
  .
\end{align*}
\end{solution}



\subsection{Problem 1-59}

\begin{problem}
We can derive Stirling's approximation from
an asymptotic approximation to the gamma function $\Gamma(x)$.
From the previous problem
\begin{align*}
  \Gamma(N+1) = N!
  &= \int_0^\infty e^{-x} x^N \, dx
  \\
  &= \int_0^\infty e^{N g(x)} \, dx
\end{align*}
where $g(x) = \ln x - x/N$.
%
If $g(x)$ possesses a maximum at some point, say $x_0$,
then for large $N$, $\exp(N g(x))$ will be extremely
sharply peaked at $x_0$.
%
Under this condition, the integral for $N!$
will be dominated by the contribution of the integrand
from the point $x_0$.
%
First show that $g(x)$ does, in fact,
possess at maximum at the point $x_0 = N$.
%
Expand $g(x)$ about this point,
keeping terms only up to and including
$(x-N)^2$ to get
$$
g(x) \approx g(N) - \frac{ (x - N)^2 } { 2 N^2 } + \cdots
$$
Why is there no linear term in $(x-N)$?
Substituting this expression for $g(x)$
into the integral for $N!$ and derive the asymptotic formula
\begin{equation}
  \ln N! \approx N \ln N - N + \ln (2\pi N)^{1/2}
  \label{eq:Stirling1}
\end{equation}
\end{problem}

\begin{solution}
The series expansion of $g(x)$ is
$$
  g(x) \approx g(x_0)
  + g'(x_0) (x - x_0)
  + \frac{1}{2} g''(x_0) (x - x_0)^2
  + \cdots.
$$
The maximum is reached at:
$$
  g'(x_0) = \frac{1}{x_0} - \frac{1}{N} = 0,
$$
or at $x_0 = N$.
This is why the linear term vanishes.
%
At this point, $g(x_0) = \ln N - 1$
and the second derivative
$$
  g''(x_0) = -\frac{1}{x_0^2} = -\frac{1}{N^2}.
$$
%
Thus,
\begin{align*}
  N!
  &= \int_0^\infty e^{Ng(x)} dx
  \approx
  e^{Ng(x_0)}
  \int_0^\infty
  e^{- \frac{(x-N)^2}{2N} } dx
  \\
  &\approx
  e^{Ng(x_0)}
  \int_{-\infty}^\infty
  e^{- \frac{(x-N)^2}{2N} } dx
  =
  e^{N(\ln N - 1)} \sqrt{2\pi N}
\end{align*}
%
Taking the logarithm, we get Eq. \eqref{eq:Stirling1}.
\end{solution}

\section{Lecture 4: Second and Third Laws}

\subsection{Problem 1-51}

\begin{problem}
  Use the method of undetermined multipliers to show that
  $$
  -\sum_{j=1}^N P_j \ln P_j
  $$
  subject to the condition
  $$
  \sum_{j=1}^N P_j = 1
  $$
  is a maximum when $P_j = \mathrm{constant}$.
\end{problem}

\begin{solution}
The function to maximize is
$$
F(\{P_j\}) = -\sum_{j=1}^N P_j \ln P_j - \alpha \left( \sum_{j=1}^N P_j - 1 \right).
$$
Taking derivatives
$$
  0 = \frac{ \partial F } { \partial P_j }
  =
  -\ln P_j - 1 - \alpha,
$$
and $P_j = e^{-1-\alpha}$ which is a constant.
\end{solution}

\subsection{Problem 2-6}

\begin{problem}
Maximize the function defined as ``information'' in information theory,
$$
I = \sum_j P_j \ln P_j
$$
subject to the two constraints
\begin{equation}
  \sum_j P_j = 1
  \label{eq:sumPj}
\end{equation}
and
\begin{equation}
  \sum_j E_j P_j = E = \mathrm{fixed}
  \label{eq:sumEjPj}
\end{equation}
Compare this result to that of Problem 1-51.

[Note: the leading word should read ``minimize''
  instead of ``maximize.'']
\end{problem}

\begin{solution}
The function to minimize is
$$
F(\{P_j\}) = \sum_{j=1}^N P_j \ln P_j
  + \alpha \left( \sum_{j=1}^N P_j - 1 \right)
  + \beta \left( \sum_{j=1}^N E_j P_j - E \right).
$$
Taking the derivative with respect to $P_j$,
$$
  0 = \frac{ \partial F } { \partial P_j }
  =
  \ln P_j + 1 + \alpha + \beta \, E_j,
$$
and $P_j = e^{-1-\alpha-\beta \, E_j}$.
%
The constants $\alpha$ and $\beta$
are determined from Eqs. \eqref{eq:sumPj} and \eqref{eq:sumEjPj}.
\end{solution}


\subsection{Problem 2-8}

\begin{problem}
  Differentiating Eq. (2-16) with respect to $\beta$
  to derive Eq. (2-13).
  \begin{align}
    Q(N, V, \beta)
    &= \sum_j e^{-\beta E_j(N, V)}
    \tag{2-16}
    \\
    \bar E = \bar E(N, V, \beta)
    &=
    \frac{ \sum_j E_j(N, V) \, e^{-\beta E_j(N, V)} }
         { \sum_j e^{-\beta E_j(N, V) } }
    \tag{2-13}
  \end{align}
\end{problem}

\begin{solution}
Differentiating (2-16), we get
\begin{align*}
  \frac{ \partial Q(N, V, \beta) } { \partial \beta }
  = -\sum_j E_j(N, V) \, e^{-\beta E_j(N, V)}.
\end{align*}
So
\begin{align*}
  -\frac{ \partial \ln Q } { \partial \beta }
  =
  -\frac{1}{Q}
  \frac{ \partial Q } { \partial \beta }
  &=
  \frac{ \sum_j E_j(N, V) \, e^{-\beta E_j(N, V)} }
       { \sum_j e^{-\beta E_j(N, V)} }
  \\
  &=\bar E(N, V, \beta)
  .
\end{align*}
\end{solution}

\section{Lecture 5: Idea of Ensembles}

\subsection{Programming problem}

\begin{problem}
Write a program to estimate $\pi$ from Monte Carlo integration.
%
Pick points randomly on a unit square.
%
Some points will lie inside a circle inscribed in the square,
some outside.
%
Use the ratio of the hits inside to the total number of trials
to estimate the area of the circle and therefore $\pi$.
%
How does it converge with the number of attempts.
\end{problem}

\begin{solution}
A sample Python program is listed below.
The error should scale
with the number of sampling points, $N$,
as $1/\sqrt N$.

\begin{lstlisting}[language=Python]
import math, random
def estpi(n):
    hits = 0
    for i in range(n):
        x = random.random() * 2 - 1
        y = random.random() * 2 - 1
        if x*x + y*y < 1:
            hits += 1
    p = 4.0*hits/n
    print "pi %g, error %g" % (p, p - math.pi)

estpi(10000)
\end{lstlisting}
\end{solution}



\section{Lecture 6: The Principles of A Priori Probabilities}

\subsection{Problem 2-11}

\begin{problem}
  Derive Eqs. (2-31) through (2-33)
  by starting with $A = -kT\ln Q$.
  \begin{align*}
    \overline E
    &=
    kT^2 \left(
      \frac{ \partial \ln Q }
           { \partial T }
    \right)_{N, V}
    \label{eq:Ebar_from_lnQ}
    \tag{2-31}
    \\
    \overline p
    &=
    kT \left(
      \frac{ \partial \ln Q }
           { \partial V }
    \right)_{N, T}
    \label{eq:pbar_from_lnQ}
    \tag{2-32}
    \\
    S
    &=
    kT \left(
      \frac{ \partial \ln Q }
           { \partial T }
    \right)_{N, V}
    + k \ln Q
    \label{eq:S_from_lnQ}
    \tag{2-33}
  \end{align*}
\end{problem}

\begin{solution}
For Eq. \eqref{eq:Ebar_from_lnQ},
see Problem 2-8.

For Eq. \eqref{eq:pbar_from_lnQ},
\begin{align*}
\left(
      \frac{ \partial \ln Q }
           { \partial V }
    \right)_{N, T}
&=
  (-\beta)
  \frac{ \sum_j (\partial E_j /\partial V) \, e^{-\beta \, E_j} }
       { \sum_j e^{-\beta \, E_j} }
\\
&=
  (-\beta)
  \frac{ \sum_j p_j \, e^{-\beta \, E_j} }
       { \sum_j e^{-\beta \, E_j} }
= -\beta \, \overline p.
\end{align*}

For Eq. \eqref{eq:S_from_lnQ}, we start with the first law
$dE = T dS - p dV + \mu dN$, or for $A = E - TS$, we have
$dA = -S dT - p dV + \mu dN$.
%
\begin{align*}
  S &=
  -
  \left( \frac{ \partial A }{ \partial T } \right)_{N, V}
  =
  \left( \frac{ \partial \, ( kT \ln Q) } { \partial T } \right)_{N, V}
  \\
  &=
  kT
  \left( \frac{ \partial \ln Q } { \partial T } \right)_{N, V}
  + k \ln Q.
\end{align*}

For Eqs. \eqref{eq:Ebar_from_lnQ} and \eqref{eq:pbar_from_lnQ},
the thermodynamic interpretation follows from the first law
$$\beta dE = d(S/k) - \beta \, p \, dV + \beta \, \mu \, dN,$$
and
$$d(S/k-\beta E) = -E \, d\beta + \beta \, p \, dV - \beta \, \mu \, dN.$$
With $S/k -\beta E = -\beta A = \ln Q$, we get
$$d \ln Q = -E \, d\beta + \beta \, p \, dV - \beta \, \mu \, dN,$$
which means
\begin{align*}
  E &= -
  \left( \frac{ \partial \ln Q } { \partial \beta } \right)_{N, V}
   =
  kT^2 \left( \frac{ \partial \ln Q } { \partial T } \right)_{N, V}, \\
  \beta \, p &=
  \left( \frac{ \partial \ln Q } { \partial V } \right)_{N, T}.
\end{align*}
\end{solution}



\subsection{Problem 2-13}

\begin{problem}
  Show that for a particle confined to a cube of length $a$ that
  $$
  p_j = \frac 2 3 \frac{ E_j } { V }
  $$
  By taking the ensemble average of both sides, we have
  $$
  \overline p = \frac 2 3 \frac{ \overline E } { V }
  $$
  If we use the fact that $\overline E = \frac 3 2 N k T$
  (to be proved in Chapter 5),
  we get the ideal gas equation of state.
\end{problem}

\begin{solution}
From quantum mechanics, we have
$$
E_j = \frac{ h^2 j^2 } { 8 m a^2 }
  =
  \frac{ h^2 j^2 } { 8 m } V^{-2/3}.
$$
From Eq. (2-14), we have for the pressure
$$
p_j = -\left( \frac{ \partial E_j } { \partial V } \right)_N
= \frac{2}{3} \frac{ h^2 j^2 } { 8 m } V^{-5/3}
= \frac{2}{3} \frac{ E_j } { V }.
$$
By averaging over the quantum states, we get
$$
  \overline p = \sum_j p_j P_j
  =
  \frac{2}{3} \frac{ \sum_j E_j P_j } { V}
  =
  \frac{2}{3} \frac{ \overline E } { V}.
$$
If $\overline E = \frac{3}{2} N k T$,
then $\overline p = \frac{ N k T } { V}$,
which is the ideal gas equation of states.
\end{solution}

\section{Lecture 7: Partition Functions and the Use of Ensembles}

\subsection{Problem 2-16}

\begin{problem}
In Chapter 13 of this author's textbook
\emph{Statistical Thermodynamics},
it is shown that the partition function of an ideal gas of diatomic molecules
in an external electric field $\mathscr E$ is
$$
Q(N, V, T, \mathscr E) = \frac{ [q(V, T, \mathscr E)]^N } { N! }
$$
where
\begin{align}
  q(V, T, \mathscr E)
  &= V \, \left( \frac{ 2 \pi m k T } { h^2 } \right)^{3/2}
  \left( \frac{ 8\pi^2 I k T } { h^2 } \right)
  \notag \\
  &\frac{ e^{-hv/2kT} } { 1 - e^{-hv/kT} }
  \left( \frac{ kT } { \mu \mathscr E } \right)
  \sinh\left( \frac{ \mu \mathscr E } { k T } \right)
\end{align}
%
where $I$ is the moment of inertia of the molecule;
$\nu$ is its fundamental vibrational frequency;
and $\mu$ is its dipole moment.
%
Using this partition function along with
the thermodynamic relation,
$$
dA = -S \, dT - p \, dV - M \, d\mathscr E
$$
where $M = N \bar\mu$,
where $\bar\mu$ is the average dipole moment
of a molecule in the direction of the external field $\mathscr E$,
show that
$$
\bar\mu = \mu \left[
  \coth\left( \frac{ \mu \mathscr E } { k T } \right)
  -\frac{ k T } { \mu \mathscr E }
  \right]
$$
Sketch this result versus $\mathscr E$
from $\mathscr E = 0$ to $\mathscr E = \infty$
and interpret it.
\end{problem}


\subsection{Problem 2-17}

\begin{problem}
In Chapter 14 we shall derive an \emph{approximate}
partition function for a dense gas,
which is of the form
$$
  Q(N, V, T)
  =
  \frac{1}{N!}
  \left( \frac{ 2\pi m k T }{ h^2 } \right)^{3N/2}
  (V - N b)^N e^{a N^2/V k T}
$$
where $a$ and $b$ are constants that are given
in terms of molecular parameters.
%
Calculate the equation of state from this partition function.
%
What equation of state is this?
%
Calculate the thermodynamic energy and the heat capacity
and compare it to Problem 1-30.
\end{problem}

\begin{solution}
The pressure can be derived from the partition function
by Eq. \eqref{eq:pbar_from_lnQ}
%
\begin{align*}
p &=
  kT \frac{ \partial \ln Q } { \partial \, V }
=
  kT \frac{ \partial \, [ N \ln (V - N b)
   + a \, N^2 / (V k T)] }
  { \partial \, V }
\\
&=
  \frac{ N k T } { V - N b} - \frac{ a N^2 }{ V^2 }
=
  \frac{ \rho \, k T } { 1 - \rho \, b} - a \rho^2
,
\end{align*}
%
where we have introduced
the number density $\rho = N/V$ in the last step.
%
The equation of state is the van der Waals equation of states,
  [cf. Eq. (14-18) on page 304].
%
From Eqs. \eqref{eq:Ebar_from_lnQ} and \eqref{eq:S_from_lnQ},
we get
\begin{align*}
\overline E
&=
    kT^2 \left(
      \frac{ \partial \ln Q }
           { \partial T }
    \right)_{N, V}
=
  \frac{ 3 N k T }{2}
  -\frac{ a N^2 } { V}
,
\\
S
&=
    kT \left(
      \frac{ \partial \ln Q }
           { \partial T }
    \right)_{N, V}
    + k \ln Q
=
  \frac{ \overline E } { T }
  + k \ln Q
,
\\
C_V
&=
\frac{ T \partial S } { \partial T }
=
\frac{ \partial \overline E } { \partial T }
= \frac{ 3 N k}{2}
.
\end{align*}
\end{solution}

\section{Lecture 8: The Canonical Ensemble}

\subsection{Problem 3-4}

\subsection{Problem 3-6}

\section{Lecture 9: Grand Canonical Ensemble}

\subsection{Problem 3-15}

\subsection{Problem 3-17}

\subsection{Problem 3-24}

\section{Lecture 10: Fluctuations}

\subsection{Problem 3-22}

\begin{problem}
Show that the fluctuation in energy in a grand canonical ensemble is
$$
\sigma_E^2 = k \, T^2 \, C_V
  + \left( \frac{\partial \overline E } { \partial \overline N} \right)_{T, V} \sigma_N^2
$$
\end{problem}

\paragraph*{Interpretations.}

There is probably a typo here, since the units do not match.
%
The most likely fix is
\begin{equation}
  \sigma_E^2 = k \, T^2 \, C_V
  + \left( \frac{\partial \overline E }
                { \partial \overline N} \right)_{T, V}
    \sigma_N^2 \, \textcolor{red}{\times \mu}
  \label{eq:prob3-22a}
\end{equation}
%
Another possible fix is
%
\begin{equation}
  \sigma_E^2 = k \, T^2 \, C_{V,\textcolor{blue}{N}}
  + \left( \frac{\partial \overline E }
                { \partial \overline N} \right)_{T, V}^{\textcolor{blue}{2}}
    \sigma_N^2
  \label{eq:prob3-22b}
\end{equation}
%
In the second correction,
$C_V$ is interpreted as the heat capacity in the canonical ensemble,
so it is less likely.

\begin{solution}
We will show Eq. \eqref{eq:prob3-22a} first.
The partition function of the grand canonical ensemble, $\Xi$,
is defined as a superposition of
the partition functions of the canonical ensemble, $Q(N, V, T)$
at various numbers of particles, $N$:
%
\begin{align}
\Xi
  &=
  \sum_{N} Q(N, V, T) \, z^N
  \notag \\
  &=
  \sum_{N, E} \Omega(N, V, E) \, e^{-\beta \, E + \mu^* \, N}
,
  \label{eq:Xi_def}
\end{align}
%
where we have defined the reduced chemical potential $\mu^* = \beta \, \mu = \ln z$.
%
As $\ln \Omega$ corresponds to the entropy $S/k$,
$\ln Q$ corresponds to the Helmholtz free energy $S/k - \beta \, E = -\beta \, A$,
the free energy corresponding to $\ln \Xi$
is the so-called grand potential:
%
\begin{equation}
  \ln \Xi
  = \frac{S}{k} - \beta \, E + \mu^* N
  = \beta \, p \, V
  .
  \label{eq:lnXi}
\end{equation}
Here, the last step follows from Euler's theorem,
$E = T \, S - p \, V + \mu \, N$ [cf. Eq. \eqref{eq:Euler}].
%
By differentiating Eq. \eqref{eq:Xi_def}, we get
%
\begin{align*}
  \frac{ \partial \Xi } { \partial \beta }
  &=
  \sum_{N, E} \Omega(N, V, E) \cdot (-E) \cdot e^{-\beta \, E + \mu^* N}
  \\
  &=
  -\Xi \,
  \sum_{N, E} E \cdot \frac{ \Omega(N, V, E) \, e^{-\beta \, E + \mu^* N} } { \Xi }
  \\
  &=
  -\Xi \times \overline{E}
  ,
\end{align*}
%
where we have collected
$\Omega(N, V, E) \, e^{-\beta \, E + \mu^* N}/\Xi$
as the joint distribution of $E$ and $N$
in the grand canonical ensemble.
%
Dividing both sides by $-\Xi$,
we get
\begin{align}
  \overline E
  &=
  -\frac{ \partial \Xi } { \Xi \, \partial \beta }
  =
  -\frac{ \partial \ln \Xi } { \partial \beta }
  ,
  \label{eq:dXidbeta}
\end{align}
Similarly, by differentiating Eq. \eqref{eq:Xi_def}
with respect to $\mu^*$, we get
\begin{align}
  \overline N &= \frac{ \partial \ln \Xi } { \partial \mu^* }
  .
  \label{eq:dXidmu}
\end{align}
%
Combining the above two results, we get
\begin{equation}
  d \ln \Xi
  =
  \frac{ \partial \ln \Xi } { \partial \beta } d\beta
  +
  \frac{ \partial \ln \Xi } { \partial \mu^* } d\mu^*
  = -\overline E \, d\beta + \overline N \, d\mu^*
  .
  \label{eq:firstlawXi}
\end{equation}
%
We can compare this to the first law of thermodynamics,
%
\begin{align}
  dE
  &= T \, dS - p \, dV + \mu \, dN
  ,
  \notag
  \\
  d\left(\frac{S}{k} \right)
  &= \beta \, dE + \beta \, p \, dV - \mu^* \, dN
  ,
  \notag
  \\
  d\left(\frac{S}{k} - \beta \, E \right)
  &= -E \, d\beta + \beta \, p \, dV - \mu^* \, dN
  ,
  \label{eq:firstlaw_bVN}
  \\
  d\left(\frac{S}{k} - \beta \, E + \mu^* N \right)
  &= -E \, d\beta + \beta \, p \, dV + N \, d\mu^*
  .
  \notag
\end{align}
%
By Eq. \eqref{eq:lnXi},
we recognize the last expression
is the differential of $\ln \Xi$,
and with a fixed volume, $V$
it becomes
%
\begin{equation}
  d\ln \Xi = -E \, d\beta + N \, d\mu^*
  .
  \label{eq:firstlawXi2}
\end{equation}
%
Thus, to make the statistical mechanical expression, Eq. \eqref{eq:firstlawXi},
agree with the thermodynamical expression, Eq. \eqref{eq:firstlawXi2},
we should interpret $E$ and $N$ in the latter
as the ensemble averages, $\overline E$ and $\overline N$, respectively.
%
We can further differentiate
Eqs. \eqref{eq:dXidbeta} and \eqref{eq:dXidmu}
to get fluctuations of $E$ and $N$:
%
\begin{align}
  \sigma_E^2
  &=
  -\left( \frac{ \partial \overline E } { \partial \beta } \right)_{\mu^*, V}
  = \frac{ \partial^2 \ln \Xi } { \partial \beta^2 }
  ,
  \label{eq:varE}
  \\
  \sigma_N^2
  &= \left( \frac{ \partial \overline N } { \partial \mu^* } \right)_{\beta, V}
  = \frac{ \partial^2 \ln \Xi } { \partial \mu^{*2} }
  \label{eq:varN}
  ,
  \\
  \left( \frac{ \partial \overline E } { \partial \mu^* } \right)_{\beta, V}
  &= -\frac{ \partial^2 \ln \Xi } { \partial \mu^* \, \partial \beta }
  = - \left( \frac{ \partial \overline N } { \partial \beta } \right)_{\mu^*, V}
  \label{eq:covEN}
  .
\end{align}

Now the heat capacity in the grand canonical ensemble can be defined as
%
\begin{align}
C_V
&= \left( \frac{ T \, \partial S } { \partial T } \right)_{\mu^*, V}
\notag \\
&= -\beta \left( \frac{ \partial S } { \partial \beta } \right)_{\mu^*, V}
= -\frac{1}{T} \left( \frac{ \partial (S/k) } { \partial \beta } \right)_{\mu^*, V}.
\label{eq:CV_def}
\end{align}
%
Using Eq. \eqref{eq:lnXi}, we have
\begin{align}
-T \, C_V
  &= \left( \frac{ \partial (\ln \Xi + \beta \, \overline E - \mu^* \, \overline N) }
  { \partial \beta } \right)_{\mu^*, V}.
  \notag
  \\
  &= \frac{ \partial \ln \Xi } { \partial \beta }
  + \overline E
  + \beta \left( \frac{ \partial \overline E } { \partial \beta } \right)_{\mu^*, V}
  - \mu^* \left( \frac{ \partial \overline N } { \partial \beta } \right)_{\mu^*, V}
  \notag
  \\
  &=
  - \beta \, \sigma_E^2
  + \mu^* \left( \frac{ \partial \overline E } { \partial \mu^* } \right)_{\beta, V}
  ,
  \notag
\end{align}
%
where we have used Eqs. \eqref{eq:dXidbeta}, \eqref{eq:varE}, and \eqref{eq:covEN}
in the last step.
%
Further using Eq. \eqref{eq:varN}, we have
\begin{equation}
T \, C_V
=
\beta \, \sigma_E^2
-
\mu^* \,
\frac{ \left( \partial \overline E / \partial \mu^* \right)_{\beta, V} }
     { \left( \partial \overline N / \partial \mu^* \right)_{\beta, V} }
\, \sigma_N^2
.
\label{eq:TCV}
\end{equation}
%
Finally, if we interpret
$$
\frac{ \left( \partial \overline E / \partial \mu^* \right)_{\beta, V} }
     { \left( \partial \overline N / \partial \mu^* \right)_{\beta, V} }
\to
\left(
  \frac{ \partial \overline E }
       { \partial \overline N }
\right)_{T, V}
,
$$
and multiply both sides of Eq. \eqref{eq:TCV} by $k T = 1/\beta$,
we recover Eq. \eqref{eq:prob3-22a}.

\paragraph*{Notes on Euler's theorem.}

For a single-component system, we have
the following useful equation
\begin{equation}
  E = T \, S - p \, V + \mu \, N.
\label{eq:Euler}
\end{equation}
%
We can show this from McQuarrie's Eq. (1-60),
$$
G = \sum_i \mu_i \, N_i
$$
But by definition $G = E - TS + pV$, so
%
$$
  E = T \, S - p \, V + \sum_i \mu_i \, N_i.
$$
%
The one-component case gives Eq. \eqref{eq:Euler}.

\paragraph*{Example on the monatomic ideal gas.}

On the monatomic ideal gas, we have
\begin{align*}
  \ln \Xi
  &= \frac{ V } { \Lambda^3 } e^{\mu^*}
  = \frac{ V (2 \, \pi \, m)^{3/2}} { h^3 } e^{\mu^*} \beta^{-3/2}
  \equiv C \, e^{\mu^*} \beta^{-3/2}
  ,
\end{align*}
where we have defind $C = V (2 \, \pi \, m)^{3/2}/h^3$.
%
Taking derivatives, we get
\begin{align*}
  \overline{ E }
  &= - \frac{ \partial \ln \Xi } { \partial \beta }
  = \frac{3}{2} C \, e^{\mu^*} \beta^{-5/2}
  ,
  \\
  \overline{ N }
  &= \frac{ \partial \ln \Xi } { \partial \mu^* }
  = C \, e^{\mu^*} \beta^{-3/2}
  ,
  \\
  \frac{ d\overline E } { d\overline N}
  &=
  \frac{3}{2\,\beta}
  ,
  \\
  \sigma_E^2
  &= - \frac{ \partial \overline{E} } { \partial \beta }
  = \frac{15}{4} \, C \, e^{\mu^*} \beta^{-7/2}
  ,
  \\
  \sigma_N^2
  &= \frac{ \partial \overline{N} } { \partial \mu^* }
  = C \, e^{\mu^*} \beta^{-3/2}
  ,
  \\
  \frac{S}{k}
  &=
  \ln \Xi + \beta \overline{E}
  -\mu^* \overline{N}
  =
  \left(\frac{5}{2} - \mu^* \right) \, C \, e^{\mu^*} \beta^{-3/2}
  ,
  \\
  \frac{C_{V, \mu^*}}{k}
  &= -\beta \left( \frac{\partial (S/k) } {\partial \beta} \right)
  = \left(\frac{15}{4} - \frac{3}{2} \, \mu^* \right)
    \, C \, e^{\mu^*} \beta^{-3/2}
  .
\end{align*}
Indeed, we have
\begin{align}
  k \, T^2 \, C_{V, \mu^*}
  =
  \sigma_E^2
  - \frac{\mu^*}{\beta} \frac{ \partial \overline E } { \partial \overline N} \sigma_N^2
  ,
\end{align}



\paragraph*{Second interpretation.}

About the second interpretation, Eq. \eqref{eq:prob3-22b},
we will use the advanced technique of transforming thermodynamic variables
(i.e. chain rule),
so please ignore this section if it sounds unfamiliar.
%
Similar to Eq. \eqref{eq:CV_def},
the heat capacity in the canonical ensemble is defined as
\begin{equation}
  C_{V, N}
  = -\frac{1}{T} \left( \frac{ \partial (S/k) } { \partial \beta } \right)_{V, N}
  .
  \label{eq:CVN_def}
\end{equation}
%
To be clear, the heat capacity in the grand canonical ensemble
will be denoted as
\begin{equation}
  C_{V, \mu^*}
  = -\frac{1}{T} \left( \frac{ \partial (S/k) } { \partial \beta } \right)_{V, \mu^*}
  .
  \label{eq:CVmu_def}
\end{equation}
%
Using the technique of determinants for transforming variables, we have
\begin{align*}
  \left( \frac{ \partial S } {\partial \beta } \right)_{\mu^*}
  &=
  \frac{ \partial (S, \mu^*) } { \partial (\beta, \mu^*) }
  =
  \left.
  \frac{ \partial (S, \mu^*) } { \partial (\beta, N) }
  \middle/
  \frac{ \partial (\beta, \mu^*) } { \partial (\beta, N) }
  \right.
  \\
  &=
  \left( \frac{ \partial S } {\partial \beta } \right)_{N}
  -
  \left.
  \left( \frac{ \partial \mu^* } {\partial \beta } \right)_{N}
  \left( \frac{ \partial S } {\partial N } \right)_{\beta}
  \middle/
  \left( \frac{ \partial \mu^* } {\partial N } \right)_{\beta}
  \right.
\end{align*}
From Eq. \eqref{eq:firstlaw_bVN}, we have
\begin{align*}
  \left( \frac{ \partial \mu^* } {\partial \beta } \right)_{N}
  &=
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  ,
  \\
  \left( \frac{ \partial (S/k) } {\partial N } \right)_{\beta}
  &=
  \left( \frac{ \partial (\frac{S}{k} - \beta \, E) } {\partial N } \right)_{\beta}
  +
  \left( \frac{ \partial ( \beta \,  E) } {\partial N } \right)_{\beta}
  \\
  &=
  -\mu^*
  +
  \beta \, \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  .
\end{align*}
Using the above two expressions, we get
\begin{align*}
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{\mu^*}
  &=
  \left( \frac{ \partial S^* } {\partial \beta } \right)_{N}
  +
  \mu^* \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  \left( \frac{ \partial N } {\partial \mu^* } \right)_{\beta}
  \\
  &-
  \beta \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}^2
  \left( \frac{ \partial N } {\partial \mu^* } \right)_{\beta}
  .
\end{align*}
%
Dividing both sides by $-1/(k T) = -\beta$,
and using Eqs. \eqref{eq:CVN_def}, \eqref{eq:CVmu_def}, and \eqref{eq:varN},
we get
$$
  k T^2 C_{V, \mu^*}
  +
  \mu \,
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}
  \sigma_N^2
  =
  k T^2 C_{V, N}
  +
  \left( \frac{ \partial E } {\partial N } \right)_{\beta}^2
  \sigma_N^2
  .
$$
If we interpret
$\left( \partial E / \partial N \right)_{\beta}$
as
$\left( \partial \overline E / \partial \overline N \right)_{T, V}$,
we recover Eq. \eqref{eq:prob3-22b}.
Note that we have implicitly assumed that $V$ is fixed in the above derivation.
\end{solution}




\subsection{Problem 3-23}

\begin{problem}
Show that in a two-component open, isothermal ensemble that
  \begin{align*}
    \overline{ N_1 \, N_2 }
    - \overline{N_1} \, \overline{N_2}
    &=
    kT \left(
      \frac{ \partial \overline{ N_1 } }
           { \partial \mu_2 }
      \right)_{V, T, \mu_1}
    \\
    &=
    kT \left(
      \frac{ \partial \overline{ N_2 } }
           { \partial \mu_1 }
      \right)_{V, T, \mu_2}
  \end{align*}
\end{problem}

\begin{solution}
The partition function of the grand canonical ensemble, $\Xi$,
is defined as a superposition of
the partition functions of the canonical ensemble, $Q(N_1, N_2, V, T)$
at various numbers of particles, $N_1$ and $N_2$,
of the two species:
\begin{align}
\Xi(\mu_1, \mu_2, V, T)
=
\sum_{N_1, N_2=0}^\infty
  Q(N_1, N_2, V, T) \,
  e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}.
\label{eq:Xi2_def}
\end{align}
%
This means that the joint distribution of $N_1$ and $N_2$
would be given by
$$
p(N_1, N_2) = \frac{ Q(N_1, N_2, V, T) \, e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2} }
                   { \Xi(\mu_1, \mu_2, V, T) }.
$$
By differentiating Eq. \eqref{eq:Xi2_def},
we have
\begin{align}
  \frac{ \partial \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 }
  &=
  \sum_{N_1, N_2}
    (\beta \, N_1) \times Q \cdot
    e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}
  \label{eq:dXi2_dmu1a}
  \\
  &=
    \beta \, \Xi \cdot
    \sum_{N_1, N_2}
    N_1 \times p(N_1, N_2)
  \notag
  \\
  &=
    \beta \, \Xi \cdot
    \overline{ N_1 }
  .
  \label{eq:dXi2_dmu1c}
\end{align}
%
Dividing both sides by $\Xi$, we get
%
\begin{align*}
  \frac{ \partial \ln \Xi } { \partial \mu_1 }
  = \beta \cdot \overline{ N_1 },
\end{align*}
%
Similarly, we have
\begin{align}
  \frac{ \partial \ln \Xi } { \partial \mu_2 }
  = \beta \cdot \overline{ N_2 },
  \label{eq:dlnXi2_dmu2}
\end{align}
%
If we further differentiate Eq. \eqref{eq:dXi2_dmu1a}
with respect to $\mu_2$, then
\begin{align*}
  \frac{ \partial^2 \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 \partial \mu_2 }
  &=
  \sum_{N_1, N_2}
    Q \cdot (\beta^2 \, N_1 \, N_2) \cdot
    e^{\beta \, \mu_1 \, N_1 + \beta \, \mu_2 \, N_2}
  \\
  &=
    \beta^2 \, \Xi \cdot
    \sum_{N_1, N_2}
    p(N_1, N_2) \cdot (N_1 \, N_2)
  \\
  &=
  \beta^2 \, \Xi \, \overline{ N_1 \, N_2 }
  .
\end{align*}
%
But if we differentiate Eq. \eqref{eq:dXi2_dmu1c}
with respect to $\mu_2$,
\begin{align*}
  \frac{ \partial^2 \Xi(\mu_1, \mu_2, V, T) }
       { \partial \mu_1 \partial \mu_2 }
  &=
    \beta \, \frac{ \partial \Xi } { \partial \mu_2 } \cdot
    \overline{ N_1 }
    +
    \beta \, \Xi \cdot
    \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  \\
  &=
    \beta^2 \, \Xi \cdot
    \overline{ N_2 } \, \overline{ N_1 }
    +
    \beta \, \Xi \cdot
    \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
\end{align*}
%
where we have used Eq. \eqref{eq:dlnXi2_dmu2} in the second step.
To make the two expressions agree, we have
$$
  \beta^2 \, \Xi \, \overline{ N_1 \, N_2 }
  =
  \beta^2 \, \Xi \cdot
  \overline{ N_2 } \, \overline{ N_1 }
  +
  \beta \, \Xi \cdot
  \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
$$
and by eliminating $\beta^2 \, \Xi$
on both sides, we get
$$
  \overline{ N_1 \, N_2 }
  =
  \overline{ N_2 } \, \overline{ N_1 }
  +
  kT \,
  \frac{ \partial \overline{ N_1 } } { \partial \mu_2 }
  ,
$$
%
which is the desired result.
%
The second equation can be shown by swapping the indices for $1$ and $2$.
\end{solution}




\section{Lecture 11: Quantum vs. Classical Statistics}

(No problem.)

\section{Lecture 12: Ideal Monatomic Gas}

\subsection{Derive the thermodynamic potential for $(\mu, p, T)$}

\begin{problem}
Derive the thermodynamic potential for the $(\mu, p, T)$ ensemble.
\end{problem}

\begin{solution}
The answer is that no such thermodynamic potential exists.

If there were a thermodynamic potential for the $(\mu, p, T)$ ensemble,
the independent variables would be $\beta$, $\beta \, p$ and $\beta \, \mu$.
%
The partition function would look like
\begin{align*}
  \Psi
  &=
  \sum_V \Xi(N, V, \beta) \, e^{-\beta \, p \, V}
  \\
  &=
  \sum_V \sum_N Q(N, V, \beta) \, e^{\beta \, \mu \, N} \, e^{-\beta \, p \, V}
  \\
  &=
  \sum_V \sum_N \sum_E \Omega(N, V, E) \, e^{-\beta \, E}
  \, e^{\beta \, \mu \, N} \, e^{-\beta \, p \, V}
  .
\end{align*}
%
Let us now recall the process of mapping
partition functions to thermodynamic potentials.
%
For the microcanonical ensemble,
we map the logarithm of the density of states,
$\ln \Omega(N, V, E)$,
to the entropy, $S/k$.

The canonical partition function is
$Q(N, V, T) = \sum_E \Omega(N, V, E) \, e^{-\beta \, E}$,
and its logarithm corresponds to
$$
\ln Q(N, V, T) = S/k - \beta \, E = -\beta \, A,
$$
where $A = E - T \, S$ is the Helmholtz free energy.

Similarly, the partition function
of the grand canonical ensemble is
$\Xi(\mu, V, T) = \sum_N Q(N, V, T) \, e^{\beta \, \mu \, N}$,
and its logarithm corresponds to
$$
\ln \Xi(\mu, V, T) = \ln Q(N, V, T) + \beta \, \mu \, N = -\beta \, (A - \mu \, N).
$$
But from Euler's theorem, $E = T \, S - p \, V + \mu \, N$
[cf. Eq. \eqref{eq:Euler}], we know that
$$
A - \mu N = E - T S - \mu N = -p \, V,
$$
and
\begin{equation}
  \ln \Xi(\mu, V, T) = \beta \, p \, V.
\label{eq:lnXi_bpV}
\end{equation}

Finally, for our thermodynamic potential, $\Psi(\mu, V, T)$,
we would have
$$
\ln \Psi(\mu, p, T) = \ln \Xi(\mu, V, T) - \beta \, p \, V.
$$
But from Eq. \eqref{eq:lnXi_bpV},
the expression on the right-hand side is simply zero,
which means that such a thermodynamic potential
would not exist (under the above mapping to thermodynamics).
\end{solution}

\paragraph*{Another explanation.}

There is actually a simpler explanation.
%
A thermodynamic potential must be an extensive quantity,
which means that it should grow linearly with the system size.
%
But since $\mu$, $p$, and $T$ are all intensive quantities,
there is no way to specify how big the system is
and to write down the thermodynamic potential.

\paragraph*{Further discussion.}

The above argument is based on thermodynamics.
%
If we rely completely on the mathematics of statistical mechanics,
we will find that either $\ln \Psi(\mu, p, T)$
would vanish in the thermodynamic limit,
i.e. its magnitude is $\mathcal O(1)$,
or the integral for $\Psi(\mu, p, T)$ would diverge.
%
It is instructive to see this on the ideal-gas case.
%
Here, we have
\begin{align*}
  Q(N, V, T)
  &= \frac{(V/\Lambda^3)^N} {N!}, \\
  \Xi(\mu, V, T)
  &= \sum_{N=0}^\infty Q(N, V, T) \, e^{\beta \mu N}
  =
  \exp\left[
    \frac{ V \, e^{\beta \mu} } { \Lambda^3 }
  \right]
  .
\end{align*}
Then, for $\Psi(\mu, p, T)$, we have
$$
\Psi(\mu, p, T)
=\sum_{V}
  \exp\left[
    \frac{ V \, e^{\beta \mu} } { \Lambda^3 }
  \right]
  e^{-\beta \, p \, V}
\equiv
\sum_{V} e^{-\beta \, (p - p^*) \, V},
$$
where $p^* = kT \, e^{\beta \mu}/\Lambda^3$
%
Since the volume is continuous,
we should replace the sum $\sum_V \cdots$
with an integral $\int C(V) \, dV \cdots$
with some proper coefficient, $C(V)$.
%
If we assume that
$C(V)$ is a constant that does not depend on $V$,
then
\begin{align*}
\Psi(\mu, p, T)
&\propto
\int_0^\infty dV \, e^{-\beta \, (p - p^*) \, V}
\\
&=
\begin{dcases}
  \frac{1}{\beta (p - p^*)} & \mbox{if $p > p^*$} \\
  +\infty & \mbox{if $p \le p^*$},
\end{dcases}
\end{align*}
%
In the case of $p \ge p^*$,
although $\Psi(\mu, p, T)$ exists,
its magnitude is of order $\mathcal O(1)$,
i.e. $\ln \Psi(\mu, p, T)$
is not an extensive quantity,
and hence cannot represent a physical thermodynamic potential.


\subsection{Problem 5-9}

\begin{problem}
  Calculate the De Broglie wavelength of an argon atom at $25^{\circ}$C
  and compare this with the average interatomic spacing at $1$atm.
\end{problem}

\begin{solution}
The atomic weight of an Argon atom is
$39.948 \mathrm{g/mol} = 6.63352136\times 10^{-26} \mathrm{kg}$,
and the (thermal) De Broglie wavelength
\begin{align*}
\Lambda
  &= \frac{h}{ \sqrt{2\,\pi\,m_\mathrm{Ar}\,k\,T} }
  \\
  &= \frac{ 6.626070040 \times 10^{-34} }
  { \sqrt{2 \, \pi \, m_\mathrm{Ar} \cdot 1.38064852 \times 10^{-23} \cdot 298.15} }
  \\
  &\approx 1.6\times10^{-11}\mathrm{m} = 0.16\mathrm{\AA}.
\end{align*}

On the other hand,
the average interatomic spacing
  is given by $L = \sqrt[3]{V}$,
where the volume follows the ideal-gas-law $pV = kT$:
\begin{align*}
  L
  &= \left(\frac{ kT } { p} \right)^{1/3}
  = \left(
  \frac{ 1.38064852 \times 10^{-23} \cdot 298.15 }
  { 101325 } \right)^{1/3}
  \\
  &\approx 3.4\times10^{-9} \mathrm{m}
  = 34\mathrm{\AA},
\end{align*}
which is much larger than the thermal De Broglie wavelength.
%
\end{solution}

\subsection{Problem 5-14}

\begin{problem}
  Derive the standard thermodynamic formula for the entropy of mixing
  by starting with Eq. (5-20) (the Sackur-Tetrode equation):
  \begin{equation}
    S = N k \ln \left[
      \left( \frac{ 2 \, \pi \, m \, k \, T } { h^2 }
      \right)^{3/2}
      \frac{ V e^{5/2} } { N }
      \right] + S_\mathrm{elec}
    \tag{5-20}
    \label{eq:Sstd}
  \end{equation}
\end{problem}

\begin{solution}
Consider the following process.
We have two boxes of different gas
separated by a dividing partition.
%
There are $N_1$ particles of type $1$ in the first box of volume $V_1$,
and $N_2$ particles of type $2$ in the second box of volume $V_2$.
%
Upon removal of the dividing partition,
particles of either type would have volume $V = V_1 + V_2$,
and the change of entropy is given by
%
\begin{align*}
  \Delta S
  &=
    \bigl[ S(N_1, V) - S(N_1, V_1) \bigr]
  + \bigl[ S(N_2, V) - S(N_2, V_2) \bigr]
  .
\end{align*}
%
From Eq. \eqref{eq:Sstd}, we have
\begin{align}
  \Delta S
  &=
  N_1 k \ln \frac{V}{V_1}
  +
  N_2 k \ln \frac{V}{V_2}.
  \label{eq:Smix1}
\end{align}
%
If we define the molar fractions
$$x_i = \frac{ N_i } { N } = \frac{ N_i } { N_1 + N_2 }$$
for $i = 1, 2$,
and assume that the volume fractions are the same
$$x_i = \frac{ V_i } { V } = \frac{ V_i } { V_1 + V_2 },$$
then Eq. \eqref{eq:Smix1} can be rewritten as
$$
\Delta S = -k \, N (x_1 \ln x_1 + x_2 \ln x_2),
$$
which is standard formula for the entropy of mixing.
[Cf. Terrell L. Hill,
  \emph{An Introduction to Statistical Thermodynamics},
  pages 81 and 85. ]
\end{solution}


\section{Lecture 13: Ideal Diatomic Gas}

\subsection{Problem 6-19}

\begin{problem}
Show that the thermodynamic quantities $p$ and $C_V$
are independent of the choice of a zero of energy.
\end{problem}

\begin{solution}
We start from the first law
$$dE = T \, dS - p \, dV + \mu \, dN.$$
If we understood $E$ as a function $S, V, N$,
then
$$
  dE(S, V, N)
  =
   \left( \frac{\partial E}{\partial S} \right)_{V, N} dS
  +\left( \frac{\partial E}{\partial V} \right)_{S, N} dV
  +\left( \frac{\partial E}{\partial N} \right)_{S, V} dN
  .
$$
This means
\begin{align*}
  p = -\left( \frac{\partial E}{\partial V} \right)_{S, N},
\end{align*}
and the zero of energy will not affect the pressure as its derivative.

Further, if fix the volume, $V$, and the number of particles, $N$,
then $dE = T \, dS$,
and the heat capacity
$$
  C_V \equiv \left( \frac{ T \, dS } { dT } \right)_{V, N}
  = \left( \frac{ \partial E } { \partial T } \right)_{V, N}.
$$
Again, as a derivative of the energy,
the heat capacity will not be affected by the zero of energy.
\end{solution}


\subsection{Show that when $kT \gg h\nu$, $q_\mathrm{vib} = kT/(h\nu)$.}

\begin{problem}
Show that when $kT \gg h\nu$, $q_\mathrm{vib} = kT/(h\nu)$.
\end{problem}

\begin{solution}
  (\emph{Due to Alec Fraser.})

We start from the quantum mechanical expression,
$$
q_\mathrm{vib} = \frac{e^{-\beta h\nu/2}}{1- e^{-\beta h\nu}}.
$$
Since $kT \gg h\nu$, we have $\beta h\nu \ll 1$,
which allows us to use the series expansion on $x = \beta h \nu$
around $x = 0$:
%
$$
e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots \approx 1 + x.
$$
%
So, with $x = \beta h \nu$ and $x = \beta h \nu/2$, we get
$$
e^{-\beta h \nu} \approx 1 - \beta h \nu,
\quad
\mbox{and}
\quad
e^{-\beta h \nu/2} \approx 1 - \beta h \nu/2.
$$
Thus,
$$q_\mathrm{vib} \approx
\frac{1-\beta h\nu/2}{1- (1-\beta h\nu)}
\approx
\frac{1}{\beta h\nu} = \frac{kT}{h\nu}.
$$
\end{solution}


\section{Lecture 14: Classical Statistical Mechanics}

\subsection{Problem 7-15}

\begin{problem}
  Convert Eq. (7-40) (see Problem 7-13)
  \begin{align}
    &f(p_x, p_y, p_z) \, d p_x \, d p_y \, d p_z
    \notag \\
    &=
    (2 \pi m k T)^{-3/2}
    e^{-(p_x^2 + p_y^2 + p_z^2) / 2 m k T}
    d p_x \, d p_y \, d p_z
    \tag{7-40}
  \end{align}
  from a Cartesian coordinate to
  a spherical coordinate representation
  by writing
  \begin{align*}
    &p^2 = p_x^2 + p_y^2 + p_z^2 \\
    &p_x = p \, \cos\theta \\
    &p_y = p \, \sin\theta \, \cos\phi \\
    &p_z = p \, \sin\theta \, \sin\phi \\
    &d p_x \, d p_y \, d p_z
    \to p^2 \sin\theta d p \, d\theta \, d\phi
  \end{align*}
  and integrating over $\theta$ and $\phi$ to get
  $$
  f(p) \, dp
  =
  4 \pi (2\pi m k T)^{-3/2} p^2 e^{-p^2/2mkT} dp
  $$
  for the fraction of molecules
  with momentum between $p$ and $p+dp$.
  %
  By substituting $p = mv$,
  we get the fraction of molecules with \emph{speeds}
  between $v$ and $v+dv$:
  $$
  f(v) \, dv
  =
  4 \pi \, \left( \frac{ m } { 2 \pi k T } \right)^{3/2}
  v^2 e^{-mv^2/2kT} \, dv
  $$
\end{problem}

\begin{solution}
Conversion to the polar coordinates:
\begin{align*}
  &\int f(p_x, p_y, p_z) \, d p_x \, d p_y \, d p_z
  \\
  &=
  \int_0^\infty
    (2\pi m kT)^{-3/2} e^{-p^2/2mkT} p^2
    d p
  \int_0^\pi \sin\theta d\theta
  \int_0^{2\pi} d\phi
  \\
  &=
  \int_0^\infty
    (2\pi m kT)^{-3/2}
    p^2 e^{-p^2/2mkT}
    d p
    \int_{-1}^{1} d(\cos\theta)
    \, (2\pi)
  \\
  &=
  \int_0^\infty
    4 \, \pi (2\pi m kT)^{-3/2}
    p^2 \, e^{-p^2/2mkT}
    d p.
\end{align*}
By substituting $p = mv$, we get
\begin{align*}
  &\int_0^\infty
    4 \, \pi (2\pi m kT)^{-3/2}
    p^2 \, e^{-p^2/2mkT}
    d p
  \\
  &=
  \int_0^\infty
    4 \, \pi (2\pi m kT)^{-3/2}
    m^2 v^2 \, e^{-m v^2/2kT}
    d (m v)
  \\
  &=
  \int_0^\infty
    4 \, \pi \left(\frac{m}{2\pi kT}\right)^{3/2}
    v^2 \, e^{-m v^2/2kT}
    d v.
\end{align*}
This shows
$$
f(v) = 4 \, \pi \left(\frac{m}{2\pi kT}\right)^{3/2}
    v^2 \, e^{-m v^2/2kT}.
$$
\end{solution}

\subsection{Problem 7-16}

\begin{problem}
  Prove that the most probable molecular speed is
  $v_{mp} = (2kT/m)^{1/2}$,
  that the mean speed is
  $\langle v \rangle = (8kT/\pi m)^{1/2}$,
  and that the root-mean-square speed is
  $\langle v^2 \rangle^{1/2} = (3kT/m)^{1/2}$.
  %
  Evaluate these for $\mathrm{H}_2$ and $\mathrm{N}_2$
  at $25^{\circ}\mathrm{C}$.

  [Hint: use Problem 7-15.]
\end{problem}

\begin{solution}
The most probable speed
occurs at the zero of $f'(v) = 0$:
$$
0 =
  2 \, v \, e^{-mv^2/2kT}
  -v^2 \, \frac{mv}{kT} \, e^{-mv^2/2kT}.
$$
which shows $v_{mp} = (2kT/m)^{1/2}$.

The mean speed is
\begin{align}
  \langle v \rangle
  &=
  \int_0^\infty v \, f(v) \, dv
  =
  \frac{4 \, a^{3/2}}{\sqrt\pi}
  \int_0^\infty
    v^3 e^{-av^2} dv
  \notag
  \\
  &=
  -\frac{2 \, a^{1/2}}{\sqrt\pi}
  \int_0^\infty
    v^2 d(e^{-av^2})
  \notag
  \\
  &=
  \frac{2 \, a^{1/2}}{\sqrt\pi}
  \left(
  -\left. v^2 \, e^{-av^2} \right|_0^\infty
  +
  \int_0^\infty
    e^{-av^2} d(v^2)
  \right)
  \notag
  \\
  &=
  -\frac{2}{\sqrt{\pi a}}
  \left.  e^{-av^2}\right|_0^\infty
  =
  \frac{2}{\sqrt{\pi a}}
  =
    \sqrt{ \frac{8kT}{m} }
  .
  \label{eq:absv_ave}
\end{align}
where $a = m/(2kT)$,
and we have integrated by parts
on the third line.
%
Another way to evaluate the integral
%
\begin{align*}
  &\int_0^\infty
    v^3 e^{-av^2} \, dv
  =
  -\frac{\partial}{\partial a}
  \int_0^\infty
    v \, e^{-av^2} \, dv
  \\
  &=
  -\frac{1}{2}
  \frac{\partial}{\partial a}
  \int_0^\infty
    e^{-av^2} \, d(v^2)
  =
  -\frac{1}{2}
  \frac{\partial}{\partial a}
    \left(  \frac{1}{a} \right)
  =\frac{1}{2 \, a^2}.
\end{align*}

For the root-mean-square speed,
\begin{align}
  \langle v^2 \rangle
  &=
  \int_0^\infty v^2 \, f(v) \, dv
  =
  \frac{4 \, a^{3/2}}{\sqrt\pi}
  \int_0^\infty
    v^4 e^{-av^2} dv
  \notag \\
  &=
  \frac{4 \, a^{3/2}}{\sqrt\pi}
    \frac{ \partial^2 } { \partial a^2 }
  \int_0^\infty
    e^{-av^2} d v
  \notag \\
  &=
  \frac{4 \, a^{3/2}}{\sqrt\pi}
    \frac{ \partial^2 } { \partial a^2 }
    \left( \frac{1}{2} \sqrt{ \frac{ \pi } { a } } \right)
  =
  \frac{3}{2 \, a}
  =
  \frac{3kT}{m}
  ,
  \label{eq:v2_ave}
\end{align}
so $\langle v^2 \rangle^{1/2} = (3kT/m)^{1/2}$.
%
Another way to evaluate this:
$$
\langle v^2 \rangle
=
\langle v_x^2 + v_y^2 + v_z^2 \rangle
=
3 \langle v_x^2 \rangle
=
\frac{ 3 k T } { m },
$$
The last step is because
the distribution of $v_x$
is the Boltzmann-Maxwell distribution.

The velocities in $\mathrm{m/s}$ are listed below:
\begin{table}[h]
\begin{tabular}{c | c c c}
  \hline \hline
  & $v_{mp}$  & $\langle v \rangle$ & $\langle v^2 \rangle^{1/2}$\\
  \hline
  $\mathrm H_2$ &
  $1.57\times10^3$ &
  $1.77\times10^3$ &
  $1.92\times10^3$\\
  $\mathrm N_2$ &
  $421$ &
  $475$ &
  $515$ \\
  \hline \hline
\end{tabular}
\end{table}
\end{solution}

\subsection{Problem 7-18}

\begin{problem}
  Show that the average velocity in any direction
  (say $x$, $y$, or $z$) vanishes.
  What does this mean?
\end{problem}

\begin{solution}
  [Due to Dr. Pettitt.]
  The Maxwell-Boltzmann distribution along the $x$ direction is
  $$
  f(v_x) d v_x = \sqrt{\frac{2\pi m }{kT}} e^{-m v_x^2/2kT} d v_x,
  $$
  which is a Gaussian distribution of width $\sqrt{kT/m}$
  centered at $0$.
  Thus, the mean is zero
  and the same holds for the distributions
  along the $y$ and $z$ directions.
  It means no net motion or transport in any direction.
\end{solution}

\section{Lecture 15: Classical Mechanics and Phase Space}

\subsection{Problem 7-6}

\begin{problem}
  Consider a perfect gas of molecules
  with permanent electric dipole moments $\boldsymbol \mu$
  in an electric field $\mathscr E$.
  %
  Neglecting the polarizability fo the molecules,
  the potential energy is
  $$
  U = -\mu \mathscr E \, \cos\theta
  $$
  where $\theta$ is the angle between $\mu$
  and $\mathscr E$.
  %
  Using classical mechanics,
  derive an expression for the additional effect of $\mathscr E$
  on the energy $E$ and heat capacity of the gas.

  Hint: see Problem 2-16, i.e. $q \sim \sinh(\beta \mu E)$.
\end{problem}


\subsection{Problem 7-17}

\begin{problem}
  Show that the mean-square fluctuation of
  the velocity of the Maxwell-Boltzmann distribution
  is
  $$
  \overline{ v^2 } - \overline{v}^2
  =
  \frac{ k T } { m }
  \left(3 - \frac{8}{\pi} \right)
  $$
\end{problem}

\begin{solution}
  This follows directly from Eqs.
  \eqref{eq:v2_ave} and \eqref{eq:absv_ave}.
\end{solution}

\section{Lecture 16: Classical Phase Space}

\subsection{Problem 7-31}

\begin{problem}
  Let $H(p, q)$ be the classical Hamiltonian
  for a classical system of $N$ interacting particles.
  %
  Let $x_j$ be one of the $3N$ momentum components
  or one of the $3N$ spatial coordinates.
  %
  Prove the generalized equipartition theorem, namely, that
  $$
  \left\langle
    x_i \frac{ \partial H } { \partial x_j }
  \right\rangle
  = kT \, \delta_{ij}
  $$
  and from this derive the principle
  of equipartition of energy that we discussed earlier.

  Hint: Realize that the potential $U \to \infty$
  at the walls of the container.
\end{problem}

\begin{solution}
If we use $x_1, x_2, \dots$, to denote
the coordinates and momenta components,
the distribution function of the canonical ensemble
is $f(x_1, x_2, \dots) = e^{-\beta H}/Q$, and
%
\begin{align*}
  \left\langle
    x_i \frac{ \partial H } { \partial x_j }
  \right\rangle
  &=
  \frac{1}{Q} \int
    x_i \frac{ \partial H } { \partial x_j }
    e^{-\beta \, H}
    d x_1 \, d x_2 \cdots
  \\
  &=
  -
  \frac{1}{\beta}
  \frac{1}{Q}
  \int_{x_{\ne j}}
    \left(
      \int_{x_j}
      x_i \frac{ \partial \, e^{-\beta \, H} } { \partial \, x_j }
      d x_j
    \right) \, d x_{\ne j}
  \\
  &=
  \frac{1}{\beta}
  \frac{1}{Q}
  \int_{x_{\ne j}}
    \left(
      \int_{x_j}
      \frac{ \partial \, x_i } { \partial \, x_j }
      e^{-\beta \, H}
      d x_j
    \right)
  \, d x_{\ne j}
  \\
  &=
  \frac{\delta_{ij}}{\beta}
  \frac{1}{Q}
  \int e^{-\beta \, H} d x
  = kT \, \delta_{ij}
  ,
\end{align*}
where we have integrated by parts on the third line,
and dropped the boundary term $x_i \, e^{-\beta H}$.
This is valid because if $x_j$ is a momentum component,
it would contribute to the Hamiltonian by $x_j^2/(2m)$
and $e^{-\beta H}$ would vanish at the boundaries,
$x_j = -\infty$ and $x_j = +\infty$.
%
But if $x_j$ is a coordinate component,
we have assumed that the potential energy, $U(x_j)$,
is infinite at the two walls,
and $e^{-\beta H}$ would also vanish
at the lower and upper limits of $x_j$.
\end{solution}

\begin{problem}
  Given a potential
  $$
  UC = \sum_{i=2} q^i
  $$
  Use Problem (7-31) to derive a general
  equipartition contribution for power law potentials.
\end{problem}

%\section{Lecture 17: Crystals, Glasses, and Polymers}
%
%\section{Lecture 18: Imperfect Gases}
%
%\section{Lecture 19: Classical Monatomic liquids}
%
%\section{Lecture 20: Density Distributions and Correlation Functions}
%
%\section{Lecture 21: Evaluating Correlation Functions}
%
%\section{Lecture 22: Equilibria and Multi-Component Systems}
%
%\section{Lecture 23: Thermodynamic Perturbation Theory}
%
%\section{Lecture 24: Electrolyte Solutions}

\end{document}

